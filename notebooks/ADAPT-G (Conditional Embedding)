{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **ADAPT-G: Adversarial Diffusion And Probabilistic Transformer-Graph for Financial Fraud Detection**\n\n---\n\n## Overview\n\n**ADAPT-G** is a novel hybrid architecture designed for **financial transaction and mobile money fraud detection**.  \nIt combines **adversarial curriculum learning with a diffusion-based generator** to create realistic synthetic fraud scenarios and a **probabilistic Transformer-Graph Neural Network (GNN) detector** to identify both **behavioral** (temporal) and **structural** (relational) anomalies.\n\nOur goal is to **push the boundaries of fraud detection** by addressing the weaknesses of traditional models in catching **stealthy, low-signal fraud patterns** — particularly those that exploit the **network relationships** between entities and **temporal transaction patterns**.\n\n---\n\n## Research Goals\n\n- **Develop** a hybrid adversarial architecture capable of detecting complex fraud signals in transaction networks.\n- **Incorporate** probabilistic reasoning into the detection stage for better uncertainty estimation and high-risk flagging.\n- **Benchmark** against state-of-the-art fraud detection models on real-world financial datasets.\n- **Evaluate** across both temporal and graph-based perspectives to capture full fraud signatures.\n\n---\n\n## Model Architecture\n\nThe **ADAPT-G** framework has two major components:\n\n1. **Diffusion-based Generator**  \n   - Generates high-quality, diverse fraudulent transaction sequences and relational patterns.  \n   - Uses **adversarial curriculum learning** to gradually create harder-to-detect fraudulent scenarios.\n\n2. **Probabilistic Transformer-GNN Detector**  \n   - **Transformer**: Models per-entity temporal transaction behavior.\n   - **Lightweight GNN**: Captures graph-level relational dependencies between entities (accounts, devices, merchants).  \n   - **Probabilistic Output Layer**: Produces calibrated uncertainty scores alongside classification outputs.\n\n---\n\n## Benchmark Models\n\nWe will compare ADAPT-G against:\n\n- **XGBoost** (tabular, feature-engineered baseline)\n- **GCN** (Graph Convolutional Network)\n- **GAT** (Graph Attention Network)\n- **Temporal GNNs** (TGAT, TGN)\n- **LSTM/GRU Autoencoders** (temporal anomaly detection baselines)\n- **TabTransformer** (tabular deep learning baseline)\n\n---\n\n## Datasets\n\nWe will evaluate on **multiple benchmark datasets** for financial/mobile money fraud detection:\n\n- **IEEE-CIS Fraud Detection** (Kaggle)\n- **PaySim** (Mobile money fraud simulation)\n- **Elliptic Dataset** (Bitcoin transaction fraud/illicit activity)\n- **SIMF Dataset** (Mobile money & transaction fraud – simulated and real-world mix)\n\nEach dataset will be preprocessed into both **tabular** and **graph-structured formats** where applicable, ensuring fair comparison across all models.\n","metadata":{}},{"cell_type":"markdown","source":"## **2. Imports & Utilities**\n\n---\n\nThis section loads all **core libraries** required for the ADAPT-G framework and defines key **utility functions** for:\n\n1. **Seeding for reproducibility** — Ensures consistent experimental results.\n2. **Metric calculations** — Precision, Recall, F1-score, AUC-ROC, and more.\n3. **Visualization** — For training/evaluation curves, ROC plots, and confusion matrices.\n","metadata":{}},{"cell_type":"code","source":"# # # Install required packages\n# # !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118  # adjust cu version or use cpu wheel\n# !pip install torch-geometric torch-scatter torch-sparse torch-spline-conv torch-cluster --quiet  # follow torch_geometric install instructions for your torch version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T20:57:41.379123Z","iopub.execute_input":"2025-08-31T20:57:41.379865Z","iopub.status.idle":"2025-08-31T20:57:41.383533Z","shell.execute_reply.started":"2025-08-31T20:57:41.379839Z","shell.execute_reply":"2025-08-31T20:57:41.382847Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ================================\n# Imports\n# ================================\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import (\n    precision_score, recall_score, f1_score,\n    roc_auc_score, roc_curve, confusion_matrix,\n    accuracy_score\n)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\n# import torchaudio\n# import torch_geometric\n# from torch_geometric.data import Data\n# from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\nfrom datetime import datetime\n\n\nimport math\nfrom typing import List, Optional, Tuple\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:36:04.004363Z","iopub.execute_input":"2025-09-09T20:36:04.004623Z","iopub.status.idle":"2025-09-09T20:36:12.054299Z","shell.execute_reply.started":"2025-09-09T20:36:04.004603Z","shell.execute_reply":"2025-09-09T20:36:12.053690Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ================================\n# Helper Functions\n# ================================\n\ndef set_seed(seed: int = 42):\n    \"\"\"\n    Sets seed for reproducibility across Python, NumPy, and PyTorch.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    print(f\"[INFO] Seed set to: {seed}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:36:18.994355Z","iopub.execute_input":"2025-09-09T20:36:18.995110Z","iopub.status.idle":"2025-09-09T20:36:18.999431Z","shell.execute_reply.started":"2025-09-09T20:36:18.995086Z","shell.execute_reply":"2025-09-09T20:36:18.998695Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# -------------------------------------------------\n# Metrics\n# -------------------------------------------------\ndef calculate_metrics(y_true, y_pred, y_prob=None):\n    \"\"\"\n    Calculate core classification metrics.\n    y_true: Ground truth labels\n    y_pred: Predicted labels\n    y_prob: Predicted probabilities (for ROC/AUC)\n    \"\"\"\n    metrics_dict = {\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n        \"F1\": f1_score(y_true, y_pred, zero_division=0)\n    }\n    if y_prob is not None:\n        metrics_dict[\"AUC-ROC\"] = roc_auc_score(y_true, y_prob)\n    return metrics_dict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:36:21.848910Z","iopub.execute_input":"2025-09-09T20:36:21.849158Z","iopub.status.idle":"2025-09-09T20:36:21.853611Z","shell.execute_reply.started":"2025-09-09T20:36:21.849141Z","shell.execute_reply":"2025-09-09T20:36:21.852858Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# -------------------------------------------------\n# Visualization Utilities\n# -------------------------------------------------\ndef plot_loss_curves(train_losses, val_losses):\n    plt.figure(figsize=(8, 5))\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training & Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_roc_curve(y_true, y_prob):\n    fpr, tpr, _ = roc_curve(y_true, y_prob)\n    auc_score = roc_auc_score(y_true, y_prob)\n    plt.figure(figsize=(6, 6))\n    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.3f}')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, labels=None):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(5, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:36:32.913370Z","iopub.execute_input":"2025-09-09T20:36:32.913639Z","iopub.status.idle":"2025-09-09T20:36:32.920166Z","shell.execute_reply.started":"2025-09-09T20:36:32.913616Z","shell.execute_reply":"2025-09-09T20:36:32.919578Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## **3. Model Architecture**\n\nThis section defines the two core components of **ADAPT-G**:\n\n---\n\n### **3.1 Generator — TabDiffusion Sample Simulator**  \nWe use **TabDiffusion** to generate **both fraudulent and non-fraudulent transaction samples**.  \n\n- **Conditional Generation:** Generator is conditioned on a label (`fraud = 0` or `1`) along with context features (merchant, device, account profile).  \n- **Dual Simulation:**  \n  - Fraudulent samples: Rare anomalies, generated to mimic realistic fraud signatures.  \n  - Non-fraudulent samples: Plausible “normal” transactions to maintain balance and realism.  \n- **Adversarial Curriculum:** Generator evolves to create increasingly **hard-to-discriminate samples**, forcing the detector to improve.  \n\n> Unlike standard anomaly generation approaches, TabDiffusion provides **balanced synthetic data augmentation** for both classes, addressing fraud rarity while avoiding biased training.  \n\n---\n\n### **3.2 Detector — Probabilistic Transformer-GNN**  \nThe detector integrates **graph structure** and **temporal behavior** to validate whether a given transaction is fraudulent or not:  \n\n- **Graph Encoder (GNN):** Captures structural dependencies across accounts, devices, and merchants.  \n- **Transformer Encoder:** Models sequential patterns in entity transaction histories.  \n- **Fusion Layer:** Combines graph + temporal embeddings.  \n- **Probabilistic Output Layer:**  \n  - Produces fraud classification (fraud vs. non-fraud).  \n  - Estimates prediction uncertainty via **MC Dropout**.  \n\n---\n\n### **3.3 Joint Training Paradigm**  \n- Generator (TabDiffusion) produces both **fraudulent and non-fraudulent samples**.  \n- Detector (Transformer-GNN) learns to confirm whether transactions are truly fraudulent or not.  \n- Adversarial training loop ensures:  \n  - Generator creates challenging, realistic samples.  \n  - Detector improves robustness by distinguishing real vs synthetic and fraud vs non-fraud simultaneously.  ","metadata":{}},{"cell_type":"markdown","source":"### **4.1 Generator: Tabular Diffusion**","metadata":{}},{"cell_type":"code","source":"# TabDiffusion-style mixed-type conditional generator (Transformer denoiser + mixed-type sampler)\n# Notebook-ready, experiment-ready implementation.\n# Author: (adapted for ADAPT-Fraud)\n# Requirements: torch >=1.12, (GPU highly recommended)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T20:57:50.607957Z","iopub.execute_input":"2025-08-31T20:57:50.608163Z","iopub.status.idle":"2025-08-31T20:57:50.621846Z","shell.execute_reply.started":"2025-08-31T20:57:50.608149Z","shell.execute_reply":"2025-08-31T20:57:50.621196Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def fourier_time_embed(t, dim, max_freq=10.0):\n    \"\"\"\n    Map scalar timestep t ∈ [0,1] into high-d Fourier features.\n    Args:\n        t: Tensor [B]\n        dim: embedding dimension\n        max_freq: highest frequency for Fourier features\n    Returns:\n        [B, dim]\n    \"\"\"\n    device = t.device\n    half = dim // 2\n    freqs = torch.linspace(1.0, max_freq, half, device=device)\n    angles = t[:, None] * freqs[None, :] * 2 * math.pi\n    emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1)\n    if dim % 2 == 1:  # pad if odd\n        emb = torch.cat([emb, torch.zeros(B, 1, device=device)], dim=-1)\n    return emb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:36:40.274184Z","iopub.execute_input":"2025-09-09T20:36:40.274852Z","iopub.status.idle":"2025-09-09T20:36:40.279314Z","shell.execute_reply.started":"2025-09-09T20:36:40.274827Z","shell.execute_reply":"2025-09-09T20:36:40.278721Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class TabDiffusionGenerator(nn.Module):\n    def __init__(\n        self,\n        num_numeric: int,\n        cat_cardinalities: List[int],\n        cond_columns: dict,   # {name: type} -> \"cat\" or \"num\"\n        token_dim: int = 192,\n        time_embed_dim: int = 128,\n        transformer_layers: int = 4,\n        transformer_heads: int = 4,\n        transformer_ff: int = 512,\n        uncond_prob: float = 0.1\n    ):\n        \"\"\"\n        Args:\n            num_numeric: number of numeric feature columns\n            cat_cardinalities: list of cardinalities for categorical feature embeddings\n            cond_columns: dict mapping column_name -> \"cat\"/\"num\"/\"binary\"\n                          These are the conditioning signals (fraud bit, day-of-week, etc.)\n            token_dim: dimension of all token embeddings\n        \"\"\"\n        super().__init__()\n        self.num_num = num_numeric\n        self.cat_cardinalities = cat_cardinalities\n        self.cond_columns = cond_columns\n        self.token_dim = token_dim\n        self.time_embed_dim = time_embed_dim\n        self.uncond_prob = uncond_prob\n\n        # =============================\n        # Input feature embeddings\n        # =============================\n        self.num_proj = nn.Linear(1, token_dim)\n        self.cat_embeds = nn.ModuleList([\n            nn.Embedding(card, token_dim) for card in cat_cardinalities\n        ])\n\n        # =============================\n        # Conditioning embeddings\n        # =============================\n        self.cond_embeds = nn.ModuleDict()\n        for col, ctype in cond_columns.items():\n            if ctype == \"cat\":\n                # must pass in cardinality for cond column\n                raise ValueError(f\"Need cardinality for cond column {col}\")\n            elif ctype == \"num\":\n                self.cond_embeds[col] = nn.Linear(1, token_dim)\n            elif ctype == \"binary\":\n                self.cond_embeds[col] = nn.Embedding(2, token_dim)\n\n        # Time embedding\n        self.time_proj = nn.Linear(time_embed_dim, token_dim)\n\n        # Projection for combining all cond signals into a single token\n        cond_in_dim = token_dim * (1 + len(self.cond_embeds))  # time + conds\n        self.cond_proj = nn.Linear(cond_in_dim, token_dim)\n\n        # =============================\n        # Transformer backbone\n        # =============================\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=token_dim,\n            nhead=transformer_heads,\n            dim_feedforward=transformer_ff,\n            batch_first=True\n        )\n        self.model = nn.TransformerEncoder(encoder_layer, num_layers=transformer_layers)\n\n        # =============================\n        # Output projection\n        # =============================\n        self.out_proj = nn.Linear(token_dim, token_dim)\n\n    # ---- build input tokens ----\n    def _build_tokens_from_inputs(self, x_num, x_cat, cond_token):\n        toks = [cond_token.unsqueeze(1)]  # prepend cond token\n\n        if x_num is not None and x_num.numel() > 0:\n            num_tokens = []\n            for i in range(self.num_num):\n                feat = x_num[:, i:i+1]\n                num_tokens.append(self.num_proj(feat.unsqueeze(-1)))\n            toks.append(torch.cat(num_tokens, dim=1))  # [B,num_num,D]\n\n        if x_cat is not None and x_cat.numel() > 0:\n            cat_tokens = []\n            for i, emb in enumerate(self.cat_embeds):\n                cat_tokens.append(emb(x_cat[:, i]))\n            toks.append(torch.stack(cat_tokens, dim=1))  # [B,num_cat,D]\n\n        return torch.cat(toks, dim=1)  # [B, 1+num_num+num_cat, D]\n\n    # ---- conditioning token ----\n    def _cond_token(self, t, cond_batch, do_cfg_dropout=False):\n        B = t.size(0)\n        time_emb = fourier_time_embed(t, self.time_embed_dim)\n        t_proj = self.time_proj(time_emb)  # [B,D]\n\n        cond_embs = [t_proj]\n        for col, emb_layer in self.cond_embeds.items():\n            val = cond_batch[col]\n            if isinstance(emb_layer, nn.Linear):\n                cond_embs.append(emb_layer(val.unsqueeze(-1).float()))\n            else:  # embedding\n                cond_embs.append(emb_layer(val.long()))\n\n        cond_full = torch.cat(cond_embs, dim=-1)\n        cond_proj = self.cond_proj(cond_full)\n\n        # Classifier-free guidance dropout\n        if do_cfg_dropout and torch.rand(1).item() < self.uncond_prob:\n            cond_proj = torch.zeros_like(cond_proj)\n\n        return cond_proj\n\n    # ---- forward ----\n    def forward(self, x_num, x_cat, cond_batch, t):\n        cond_token = self._cond_token(t, cond_batch, do_cfg_dropout=False)\n        tokens = self._build_tokens_from_inputs(x_num, x_cat, cond_token)\n        h = self.model(tokens)\n        return self.out_proj(h)\n\n    # ---- training loss ----\n    def training_loss(self, x_num, x_cat, cond_batch):\n        B = x_num.size(0)\n        device = x_num.device\n        t = torch.rand(B, device=device)\n\n        cond_token = self._cond_token(t, cond_batch, do_cfg_dropout=True)\n        tokens_clean = self._build_tokens_from_inputs(x_num, x_cat, cond_token)\n\n        noise = torch.randn_like(tokens_clean)\n        tokens_noisy = tokens_clean + noise\n\n        pred = self.model(tokens_noisy)\n        pred = self.out_proj(pred)\n\n        return F.mse_loss(pred, tokens_clean)\n\n    # ---- sampling ----\n    @torch.no_grad()\n    def sample(self, x_num, x_cat, cond_batch, steps=50, cfg_scale=1.5):\n        device = next(self.parameters()).device\n        B = list(cond_batch.values())[0].size(0)\n\n        toks = torch.randn(B, 1 + self.num_num + len(self.cat_cardinalities), self.token_dim, device=device)\n\n        for step in reversed(range(steps)):\n            t = torch.full((B,), step / steps, device=device)\n\n            cond_token = self._cond_token(t, cond_batch, do_cfg_dropout=False)\n            toks_cond = self.model(self._build_tokens_from_inputs(x_num, x_cat, cond_token))\n\n            if cfg_scale != 1.0:\n                null_cond = self._cond_token(t, cond_batch, do_cfg_dropout=True)\n                toks_null = self.model(self._build_tokens_from_inputs(x_num, x_cat, null_cond))\n                toks_cond = toks_null + cfg_scale * (toks_cond - toks_null)\n\n            toks = self.out_proj(toks_cond)\n\n        return toks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:36:44.758861Z","iopub.execute_input":"2025-09-09T20:36:44.759133Z","iopub.status.idle":"2025-09-09T20:36:44.775620Z","shell.execute_reply.started":"2025-09-09T20:36:44.759113Z","shell.execute_reply":"2025-09-09T20:36:44.774978Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **Test TabDiffusion with a real benchmark (IEEE-CIS)**","metadata":{}},{"cell_type":"markdown","source":"[The IEEE-CIS data](https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203)\n\n\n**Load the input data**. In this case, we have two datasets: the transaction data and the identity data. \n\nEach row in the transaction data represents attributes of a specific transaction such as money transfer and also other gifting goods and service, like you booked a ticket for others, etc. and captures useful details such as transaction time, amount, payment card information, such as card type, card category, issue bank, country, etc, product or service procured (airtime, data, cable, ticket e.t.c) address, how many addresses are found to be associated with the payment card, distances between billing address, mailing address, zip code, IP address, phone area, etc. purchaser and recipient email domain, days between previous transaction, e.t.c, days between previous transaction, match, such as names on card and address, \n\nEach row in the identity dataset represents identity information such as network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with each transaction. Also, it recorded behavioral fingerprints like account login times/failed to login times, how long an account stayed on the page, etc. \n\nThe transaction_id column is the unique identifier that relates both the transaction and identity tables.","metadata":{}},{"cell_type":"code","source":"# Load datasets\ntransaction = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_transaction.csv\")\nidentity   = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_identity.csv\")\nprint(transaction.shape, identity.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:36:52.668832Z","iopub.execute_input":"2025-09-09T20:36:52.669128Z","iopub.status.idle":"2025-09-09T20:37:15.350896Z","shell.execute_reply.started":"2025-09-09T20:36:52.669104Z","shell.execute_reply":"2025-09-09T20:37:15.350198Z"}},"outputs":[{"name":"stdout","text":"(590540, 394) (144233, 41)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# merge datasets\ndf = transaction.merge(identity, on='TransactionID', how='left')\nprint(\"Merged shape:\", df.shape)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:37:29.598248Z","iopub.execute_input":"2025-09-09T20:37:29.598789Z","iopub.status.idle":"2025-09-09T20:37:30.468278Z","shell.execute_reply.started":"2025-09-09T20:37:29.598764Z","shell.execute_reply":"2025-09-09T20:37:30.467634Z"}},"outputs":[{"name":"stdout","text":"Merged shape: (590540, 434)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n0        2987000        0          86400            68.5         W  13926   \n1        2987001        0          86401            29.0         W   2755   \n2        2987002        0          86469            59.0         W   4663   \n3        2987003        0          86499            50.0         W  18132   \n4        2987004        0          86506            50.0         H   4497   \n\n   card2  card3       card4  card5  ...                id_31  id_32  \\\n0    NaN  150.0    discover  142.0  ...                  NaN    NaN   \n1  404.0  150.0  mastercard  102.0  ...                  NaN    NaN   \n2  490.0  150.0        visa  166.0  ...                  NaN    NaN   \n3  567.0  150.0  mastercard  117.0  ...                  NaN    NaN   \n4  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n\n       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n0        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n1        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n2        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n3        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n4  2220x1080  match_status:2      T     F     T      T      mobile   \n\n                      DeviceInfo  \n0                            NaN  \n1                            NaN  \n2                            NaN  \n3                            NaN  \n4  SAMSUNG SM-G892A Build/NRD90M  \n\n[5 rows x 434 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>...</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_35</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2987000</td>\n      <td>0</td>\n      <td>86400</td>\n      <td>68.5</td>\n      <td>W</td>\n      <td>13926</td>\n      <td>NaN</td>\n      <td>150.0</td>\n      <td>discover</td>\n      <td>142.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2987001</td>\n      <td>0</td>\n      <td>86401</td>\n      <td>29.0</td>\n      <td>W</td>\n      <td>2755</td>\n      <td>404.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>102.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2987002</td>\n      <td>0</td>\n      <td>86469</td>\n      <td>59.0</td>\n      <td>W</td>\n      <td>4663</td>\n      <td>490.0</td>\n      <td>150.0</td>\n      <td>visa</td>\n      <td>166.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2987003</td>\n      <td>0</td>\n      <td>86499</td>\n      <td>50.0</td>\n      <td>W</td>\n      <td>18132</td>\n      <td>567.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>117.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2987004</td>\n      <td>0</td>\n      <td>86506</td>\n      <td>50.0</td>\n      <td>H</td>\n      <td>4497</td>\n      <td>514.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>102.0</td>\n      <td>...</td>\n      <td>samsung browser 6.2</td>\n      <td>32.0</td>\n      <td>2220x1080</td>\n      <td>match_status:2</td>\n      <td>T</td>\n      <td>F</td>\n      <td>T</td>\n      <td>T</td>\n      <td>mobile</td>\n      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 434 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"**Preprocess the Dataset** by dropping irrelevant columns, dealing with the missing values, scaling the numerical columns, and encoding the categorical columns","metadata":{}},{"cell_type":"code","source":"# drop identifier columns (we won't model\ndrop_cols = ['TransactionID']  # keep TransactionDT for time_to_detect\ncandidate = df.drop(columns=drop_cols)\n\n# identify label\nlabel_col = 'isFraud'\n\n# numeric / categorical heuristics\nnum_cols = candidate.select_dtypes(include=['int64','float64']).columns.tolist()\nnum_cols = [c for c in num_cols if c != label_col]\ncat_cols = candidate.select_dtypes(include=['object']).columns.tolist()\n\nprint(\"Numeric cols:\", len(num_cols))\nprint(\"Categorical cols:\", len(cat_cols))\n# Optionally prune columns to avoid very high-cardinality ones (or group rare categories)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:37:36.182739Z","iopub.execute_input":"2025-09-09T20:37:36.183044Z","iopub.status.idle":"2025-09-09T20:37:38.828510Z","shell.execute_reply.started":"2025-09-09T20:37:36.183022Z","shell.execute_reply":"2025-09-09T20:37:38.827874Z"}},"outputs":[{"name":"stdout","text":"Numeric cols: 401\nCategorical cols: 31\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Fill NAs\ndf[num_cols] = df[num_cols].fillna(0.0)\ndf[cat_cols] = df[cat_cols].fillna('NA')\n\n# scalers & encoders\nscaler = StandardScaler()\nscaler.fit(df[num_cols].values)   # save for inference\n\nlabel_encoders = {}\n# cat_cardinalities = []\nfor c in cat_cols:\n    le = LabelEncoder()\n    df[c] = le.fit_transform(df[c].astype(str).values)\n    label_encoders[c] = le\n    # cat_cardinalities.append(len(le.classes_))\n\n# print(\"cat_cardinalities:\", cat_cardinalities[:10])\n# plt.hist(cat_cardinalities)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:37:45.618653Z","iopub.execute_input":"2025-09-09T20:37:45.619272Z","iopub.status.idle":"2025-09-09T20:37:56.876117Z","shell.execute_reply.started":"2025-09-09T20:37:45.619247Z","shell.execute_reply":"2025-09-09T20:37:56.875509Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"**Define Conditional columns:**\n\nPick and instantiate candidate conditioning variables. These are the categorical features that are mostly useful in depicting the fraud types and provide context to attributes that are associated with certain fraud types, e.g., device used, account type, product type. These columns are fed into the conditional embedding vector (cond_vec), which the diffusion generator uses as side information. This forces the generator to learn distributions conditioned on context, e.g., Fraud patterns when using Device A vs Device B or under different product categories, as against just primarily learning distributions that are fraud against non-fraud. \nThis helps the generator capture multi-modal fraud patterns. It also gives us more control: later, when sampling, we can say, “Generate fraud-like transactions for DeviceType = mobile”, such that the generator will generate different fraud/non-fraud distributions depending on such device type. So in this case, the generator can generate synthetic data of fraudulent samples when the device is \"mobile\" and non-fraudulent samples when the device is also \"mobile\". It is unable to learn this level of representation without conditioning. This is important because fraud is rarely a uniform cluster — it often manifests differently depending on context (e.g., fraud on mobile devices, fraud in online purchases, fraud with high transaction amounts). With only \"isFraud\", the generator has no way to control which type of fraud it’s generating. So these conditioning columns help the generator learn subtypes of fraud (more adversarial realism, but more complexity).","metadata":{}},{"cell_type":"code","source":"# # Choose a handful of columns to form a conditioner (identity/device + product)\n# cond_columns = [\n#     'ProductCD', 'card4', 'card6',\n#     'DeviceType', 'DeviceInfo',\n#     'id_30', 'id_31',\n#     'addr1', 'P_emaildomain', 'R_emaildomain'\n# ]\n# # cond_columns = [c for c in cond_columns if c in df.columns]\n# cond_columns = [c for c in cond_columns if c in cat_cols]\n# print(\"Using conditional columns:\", cond_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:00:08.654698Z","iopub.execute_input":"2025-09-09T20:00:08.654930Z","iopub.status.idle":"2025-09-09T20:00:08.659769Z","shell.execute_reply.started":"2025-09-09T20:00:08.654914Z","shell.execute_reply":"2025-09-09T20:00:08.658861Z"}},"outputs":[{"name":"stdout","text":"Using conditional columns: ['ProductCD', 'card4', 'card6', 'DeviceType', 'DeviceInfo', 'id_30', 'id_31', 'P_emaildomain', 'R_emaildomain']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**Build embedding lookup dictionary module** \n\nCreates an embedding table that stores the embedding of each conditioning variable with shape [n_categories, embedding_dim], where n_categories is the number of labels in each class and embedding_dim is the set embedding dimension (32 in this case); Such that each category (like visa or Windows 10) gets mapped to a learnable 32-dimensional vector and stored in a dictionary keyed by column name that allows us look up the embeddings column by column during the forward pass.\n\n","metadata":{}},{"cell_type":"code","source":"# # Make embedding layers for categorical columns and concatenate\n# CAT_EMBED_DIM = 32\n# cat_cardinalities = {c: int(df[c].nunique()) for c in cat_cols}\n# cat_emb_modules = nn.ModuleDict()\n# for c, card in cat_cardinalities.items():\n#     cat_emb_modules[c] = nn.Embedding(card, CAT_EMBED_DIM)\n# print(\"Built shared cat_emb_modules for\", len(cat_emb_modules), \"categorical columns.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:00:14.341599Z","iopub.execute_input":"2025-09-09T20:00:14.342167Z","iopub.status.idle":"2025-09-09T20:00:14.463727Z","shell.execute_reply.started":"2025-09-09T20:00:14.342122Z","shell.execute_reply":"2025-09-09T20:00:14.463159Z"}},"outputs":[{"name":"stdout","text":"Built shared cat_emb_modules for 31 categorical columns.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Dataset - returns numeric features, categorical indices, label, time, account id\nclass IEEECISDatasetTorch(Dataset):\n    def __init__(self, df, num_cols, cat_cols, label_col='isFraud', acct_col='card1', scaler=None):\n        self.df = df.reset_index(drop=True)\n        self.num_cols = num_cols\n        self.cat_cols = cat_cols\n        self.label_col = label_col\n        self.acct_col = acct_col\n        self.scaler = scaler\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        if self.num_cols:\n            x_num = torch.tensor(self.scaler.transform(row[self.num_cols].values.reshape(1,-1)).squeeze(0), dtype=torch.float32)\n        else:\n            x_num = torch.zeros(0, dtype=torch.float32)\n        x_cat = torch.tensor(row[self.cat_cols].astype(int).values, dtype=torch.long) if self.cat_cols else torch.zeros(0, dtype=torch.long)\n        y = torch.tensor(int(row[self.label_col]) if self.label_col in row else 0, dtype=torch.long)\n        tx_time = row['TransactionDT'] if 'TransactionDT' in row else np.nan\n        acct = row[self.acct_col] if self.acct_col in row else None\n        return x_num, x_cat, y, tx_time, acct\n\ndef collate_fn(batch):\n    x_num = torch.stack([b[0] for b in batch], dim=0)\n    x_cat = torch.stack([b[1] for b in batch], dim=0)\n    y = torch.stack([b[2] for b in batch], dim=0)\n    tx_time = [b[3] for b in batch]\n    acct = [b[4] for b in batch]\n    return x_num, x_cat, y, tx_time, acct\n\n# Create DataLoader\ndataset = IEEECISDatasetTorch(df, num_cols, cat_cols, label_col=label_col, acct_col='card1', scaler=scaler)\nloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)\nprint(\"Dataset and loader ready. Dataset size:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:38:03.713906Z","iopub.execute_input":"2025-09-09T20:38:03.714170Z","iopub.status.idle":"2025-09-09T20:38:06.023902Z","shell.execute_reply.started":"2025-09-09T20:38:03.714151Z","shell.execute_reply":"2025-09-09T20:38:06.023211Z"}},"outputs":[{"name":"stdout","text":"Dataset and loader ready. Dataset size: 590540\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# -------------------------------\n# Conditioning columns (as dict)\n# -------------------------------\nCOND_COLS = {\n    \"isFraud\": {\"type\": \"binary\"},\n}\nfor c in [\"ProductCD\",\"card4\",\"card6\",\"DeviceType\",\"DeviceInfo\",\"id_30\",\"id_31\",\"P_emaildomain\",\"R_emaildomain\"]:\n    COND_COLS[c] = {\"type\": \"cat\", \"cardinality\": len(label_encoders[c].classes_)}\n\n# -------------------------------\n# Build dataset metadata\n# -------------------------------\nFNUM = len(num_cols)\nCAT_CARDINALITIES = [len(label_encoders[c].classes_) for c in cat_cols]\n\n# -------------------------------\n# Device\n# -------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# -------------------------------\n# Instantiate generator\n# -------------------------------\ngen = TabDiffusionGenerator(\n    num_numeric=FNUM,\n    cat_cardinalities=CAT_CARDINALITIES,\n    cond_columns=COND_COLS,\n    token_dim=192,\n    transformer_layers=4,\n    transformer_heads=4,\n    transformer_ff=512,\n    uncond_prob=0.1\n).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:48:31.251746Z","iopub.execute_input":"2025-09-09T20:48:31.252480Z","iopub.status.idle":"2025-09-09T20:48:31.458586Z","shell.execute_reply.started":"2025-09-09T20:48:31.252454Z","shell.execute_reply":"2025-09-09T20:48:31.457819Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# import torch.optim as optim\n\n# opt = optim.AdamW(gen.parameters(), lr=2e-4)\n\n# # fetch a batch\n# batch = next(iter(loader))\n# x_num, x_cat, y, tx_time, acct = batch\n\n# x_num = x_num.to(device)\n# x_cat = x_cat.to(device)\n# y = y.to(device).float()\n\n# # --------------------------\n# # Build cond_batch dict\n# # --------------------------\n# cond_batch = {\n#     \"isFraud\": y,  # binary conditioning\n#     \"ProductCD\": x_cat[:, cat_cols.index(\"ProductCD\")],\n#     \"card4\": x_cat[:, cat_cols.index(\"card4\")],\n#     \"card6\": x_cat[:, cat_cols.index(\"card6\")],\n#     \"DeviceType\": x_cat[:, cat_cols.index(\"DeviceType\")],\n#     \"DeviceInfo\": x_cat[:, cat_cols.index(\"DeviceInfo\")],\n#     \"id_30\": x_cat[:, cat_cols.index(\"id_30\")],\n#     \"id_31\": x_cat[:, cat_cols.index(\"id_31\")],\n#     \"P_emaildomain\": x_cat[:, cat_cols.index(\"P_emaildomain\")],\n#     \"R_emaildomain\": x_cat[:, cat_cols.index(\"R_emaildomain\")]\n# }\n\n# # --------------------------\n# # Train step\n# # --------------------------\n# gen.train()\n# loss = gen.training_loss(x_num, x_cat, cond_batch)\n# opt.zero_grad()\n# loss.backward()\n# opt.step()\n\n# print('Smoke step loss:', loss.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:52:24.534705Z","iopub.execute_input":"2025-09-09T20:52:24.535447Z","iopub.status.idle":"2025-09-09T20:52:25.928635Z","shell.execute_reply.started":"2025-09-09T20:52:24.535410Z","shell.execute_reply":"2025-09-09T20:52:25.927892Z"}},"outputs":[{"name":"stdout","text":"Smoke step loss: 0.8728820085525513\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"for step, batch in enumerate(loader):\n    x_num, x_cat, y, tx_time, acct = batch\n    x_num, x_cat, y = x_num.to(device), x_cat.to(device), y.to(device).float()\n    \n    cond_batch = {\n    \"isFraud\": y,  # binary conditioning\n    \"ProductCD\": x_cat[:, cat_cols.index(\"ProductCD\")],\n    \"card4\": x_cat[:, cat_cols.index(\"card4\")],\n    \"card6\": x_cat[:, cat_cols.index(\"card6\")],\n    \"DeviceType\": x_cat[:, cat_cols.index(\"DeviceType\")],\n    \"DeviceInfo\": x_cat[:, cat_cols.index(\"DeviceInfo\")],\n    \"id_30\": x_cat[:, cat_cols.index(\"id_30\")],\n    \"id_31\": x_cat[:, cat_cols.index(\"id_31\")],\n    \"P_emaildomain\": x_cat[:, cat_cols.index(\"P_emaildomain\")],\n    \"R_emaildomain\": x_cat[:, cat_cols.index(\"R_emaildomain\")]\n}    \n    gen.train()\n    loss = gen.training_loss(x_num, x_cat, cond_batch)\n    \n    opt.zero_grad()\n    loss.backward()\n    opt.step()\n    \n    if step % 50 == 0:\n        print(f\"Step {step}, loss = {loss.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T20:55:31.632475Z","iopub.execute_input":"2025-09-09T20:55:31.633258Z","iopub.status.idle":"2025-09-09T20:55:47.867704Z","shell.execute_reply.started":"2025-09-09T20:55:31.633231Z","shell.execute_reply":"2025-09-09T20:55:47.866712Z"}},"outputs":[{"name":"stdout","text":"Step 0, loss = 1.1955\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/209220703.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":28},{"cell_type":"code","source":"# Sampling example: pick one row as a condition and generate both non-fraud and fraud samples\ngen.eval()\n# pick first row as condition\nrow_idx = 0\n_, x_cat_row, y_row, _, _ = dataset[row_idx]\n# build cond indices for cond_columns (we need indices aligned to cat_cols order)\n# cond_cat_indices is of shape [1, len(cat_cols)], but model expects all cat_cols; we'll pass full x_cat row\ncond_cat_indices = x_cat_row.unsqueeze(0).to(device)\nfraud_bit_0 = torch.tensor([0.0], device=device)\nfraud_bit_1 = torch.tensor([1.0], device=device)\n\nwith torch.no_grad():\n    num_gen_0, cat_gen_0 = gen.sample(batch_size=8, cond_cat_indices=cond_cat_indices, fraud_bits=fraud_bit_0, steps=30, guidance_w=1.2, device_local=device)\n    num_gen_1, cat_gen_1 = gen.sample(batch_size=8, cond_cat_indices=cond_cat_indices, fraud_bits=fraud_bit_1, steps=30, guidance_w=1.2, device_local=device)\n\nprint('Generated non-fraud numeric shape, cat shape:', num_gen_0.shape, cat_gen_0.shape)\nprint('Generated fraud     numeric shape, cat shape:', num_gen_1.shape, cat_gen_1.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T20:17:11.687687Z","iopub.status.idle":"2025-08-31T20:17:11.687936Z","shell.execute_reply.started":"2025-08-31T20:17:11.687825Z","shell.execute_reply":"2025-08-31T20:17:11.687836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}