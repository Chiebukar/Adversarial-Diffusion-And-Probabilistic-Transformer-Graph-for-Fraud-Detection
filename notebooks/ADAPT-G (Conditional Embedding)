{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **ADAPT-G: Adversarial Diffusion And Probabilistic Transformer-Graph for Financial Fraud Detection**\n\n---\n\n## Overview\n\n**ADAPT-G** is a novel hybrid architecture designed for **financial transaction and mobile money fraud detection**.  \nIt combines **adversarial curriculum learning with a diffusion-based generator** to create realistic synthetic fraud scenarios and a **probabilistic Transformer-Graph Neural Network (GNN) detector** to identify both **behavioral** (temporal) and **structural** (relational) anomalies.\n\nOur goal is to **push the boundaries of fraud detection** by addressing the weaknesses of traditional models in catching **stealthy, low-signal fraud patterns** — particularly those that exploit the **network relationships** between entities and **temporal transaction patterns**.\n\n---\n\n## Research Goals\n\n- **Develop** a hybrid adversarial architecture capable of detecting complex fraud signals in transaction networks.\n- **Incorporate** probabilistic reasoning into the detection stage for better uncertainty estimation and high-risk flagging.\n- **Benchmark** against state-of-the-art fraud detection models on real-world financial datasets.\n- **Evaluate** across both temporal and graph-based perspectives to capture full fraud signatures.\n\n---\n\n## Model Architecture\n\nThe **ADAPT-G** framework has two major components:\n\n1. **Diffusion-based Generator**  \n   - Generates high-quality, diverse fraudulent transaction sequences and relational patterns.  \n   - Uses **adversarial curriculum learning** to gradually create harder-to-detect fraudulent scenarios.\n\n2. **Probabilistic Transformer-GNN Detector**  \n   - **Transformer**: Models per-entity temporal transaction behavior.\n   - **Lightweight GNN**: Captures graph-level relational dependencies between entities (accounts, devices, merchants).  \n   - **Probabilistic Output Layer**: Produces calibrated uncertainty scores alongside classification outputs.\n\n---\n\n## Benchmark Models\n\nWe will compare ADAPT-G against:\n\n- **XGBoost** (tabular, feature-engineered baseline)\n- **GCN** (Graph Convolutional Network)\n- **GAT** (Graph Attention Network)\n- **Temporal GNNs** (TGAT, TGN)\n- **LSTM/GRU Autoencoders** (temporal anomaly detection baselines)\n- **TabTransformer** (tabular deep learning baseline)\n\n---\n\n## Datasets\n\nWe will evaluate on **multiple benchmark datasets** for financial/mobile money fraud detection:\n\n- **IEEE-CIS Fraud Detection** (Kaggle)\n- **PaySim** (Mobile money fraud simulation)\n- **Elliptic Dataset** (Bitcoin transaction fraud/illicit activity)\n- **SIMF Dataset** (Mobile money & transaction fraud – simulated and real-world mix)\n\nEach dataset will be preprocessed into both **tabular** and **graph-structured formats** where applicable, ensuring fair comparison across all models.\n","metadata":{}},{"cell_type":"markdown","source":"## **2. Imports & Utilities**\n\n---\n\nThis section loads all **core libraries** required for the ADAPT-G framework and defines key **utility functions** for:\n\n1. **Seeding for reproducibility** — Ensures consistent experimental results.\n2. **Metric calculations** — Precision, Recall, F1-score, AUC-ROC, and more.\n3. **Visualization** — For training/evaluation curves, ROC plots, and confusion matrices.\n","metadata":{}},{"cell_type":"code","source":"# # # Install required packages\n# # !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118  # adjust cu version or use cpu wheel\n# !pip install torch-geometric torch-scatter torch-sparse torch-spline-conv torch-cluster --quiet  # follow torch_geometric install instructions for your torch version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:32.206413Z","iopub.execute_input":"2025-09-12T10:07:32.206958Z","iopub.status.idle":"2025-09-12T10:07:32.210947Z","shell.execute_reply.started":"2025-09-12T10:07:32.206909Z","shell.execute_reply":"2025-09-12T10:07:32.210234Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ================================\n# Imports\n# ================================\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import (\n    precision_score, recall_score, f1_score,\n    roc_auc_score, roc_curve, confusion_matrix,\n    accuracy_score\n)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\n# import torchaudio\n# import torch_geometric\n# from torch_geometric.data import Data\n# from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\nfrom datetime import datetime\n\n\nimport math\nfrom typing import List, Optional, Tuple\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:32.212090Z","iopub.execute_input":"2025-09-12T10:07:32.212292Z","iopub.status.idle":"2025-09-12T10:07:40.817906Z","shell.execute_reply.started":"2025-09-12T10:07:32.212277Z","shell.execute_reply":"2025-09-12T10:07:40.817302Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ================================\n# Helper Functions\n# ================================\n\ndef set_seed(seed: int = 42):\n    \"\"\"\n    Sets seed for reproducibility across Python, NumPy, and PyTorch.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    print(f\"[INFO] Seed set to: {seed}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:40.818629Z","iopub.execute_input":"2025-09-12T10:07:40.819086Z","iopub.status.idle":"2025-09-12T10:07:40.824064Z","shell.execute_reply.started":"2025-09-12T10:07:40.819059Z","shell.execute_reply":"2025-09-12T10:07:40.823359Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# -------------------------------------------------\n# Metrics\n# -------------------------------------------------\ndef calculate_metrics(y_true, y_pred, y_prob=None):\n    \"\"\"\n    Calculate core classification metrics.\n    y_true: Ground truth labels\n    y_pred: Predicted labels\n    y_prob: Predicted probabilities (for ROC/AUC)\n    \"\"\"\n    metrics_dict = {\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n        \"F1\": f1_score(y_true, y_pred, zero_division=0)\n    }\n    if y_prob is not None:\n        metrics_dict[\"AUC-ROC\"] = roc_auc_score(y_true, y_prob)\n    return metrics_dict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:40.825901Z","iopub.execute_input":"2025-09-12T10:07:40.826166Z","iopub.status.idle":"2025-09-12T10:07:40.843810Z","shell.execute_reply.started":"2025-09-12T10:07:40.826148Z","shell.execute_reply":"2025-09-12T10:07:40.843205Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# -------------------------------------------------\n# Visualization Utilities\n# -------------------------------------------------\ndef plot_loss_curves(train_losses, val_losses):\n    plt.figure(figsize=(8, 5))\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training & Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_roc_curve(y_true, y_prob):\n    fpr, tpr, _ = roc_curve(y_true, y_prob)\n    auc_score = roc_auc_score(y_true, y_prob)\n    plt.figure(figsize=(6, 6))\n    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.3f}')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, labels=None):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(5, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:40.844669Z","iopub.execute_input":"2025-09-12T10:07:40.844920Z","iopub.status.idle":"2025-09-12T10:07:40.861056Z","shell.execute_reply.started":"2025-09-12T10:07:40.844897Z","shell.execute_reply":"2025-09-12T10:07:40.860323Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## **3. Model Architecture**\n\nThis section defines the two core components of **ADAPT-G**:\n\n---\n\n### **3.1 Generator — TabDiffusion Sample Simulator**  \nWe use **TabDiffusion** to generate **both fraudulent and non-fraudulent transaction samples**.  \n\n- **Conditional Generation:** Generator is conditioned on a label (`fraud = 0` or `1`) along with context features (merchant, device, account profile).  \n- **Dual Simulation:**  \n  - Fraudulent samples: Rare anomalies, generated to mimic realistic fraud signatures.  \n  - Non-fraudulent samples: Plausible “normal” transactions to maintain balance and realism.  \n- **Adversarial Curriculum:** Generator evolves to create increasingly **hard-to-discriminate samples**, forcing the detector to improve.  \n\n> Unlike standard anomaly generation approaches, TabDiffusion provides **balanced synthetic data augmentation** for both classes, addressing fraud rarity while avoiding biased training.  \n\n---\n\n### **3.2 Detector — Probabilistic Transformer-GNN**  \nThe detector integrates **graph structure** and **temporal behavior** to validate whether a given transaction is fraudulent or not:  \n\n- **Graph Encoder (GNN):** Captures structural dependencies across accounts, devices, and merchants.  \n- **Transformer Encoder:** Models sequential patterns in entity transaction histories.  \n- **Fusion Layer:** Combines graph + temporal embeddings.  \n- **Probabilistic Output Layer:**  \n  - Produces fraud classification (fraud vs. non-fraud).  \n  - Estimates prediction uncertainty via **MC Dropout**.  \n\n---\n\n### **3.3 Joint Training Paradigm**  \n- Generator (TabDiffusion) produces both **fraudulent and non-fraudulent samples**.  \n- Detector (Transformer-GNN) learns to confirm whether transactions are truly fraudulent or not.  \n- Adversarial training loop ensures:  \n  - Generator creates challenging, realistic samples.  \n  - Detector improves robustness by distinguishing real vs synthetic and fraud vs non-fraud simultaneously.  ","metadata":{}},{"cell_type":"markdown","source":"### **4.1 Generator: Tabular Diffusion**","metadata":{}},{"cell_type":"code","source":"# TabDiffusion-style mixed-type conditional generator (Transformer denoiser + mixed-type sampler)\n# Notebook-ready, experiment-ready implementation.\n# Author: (adapted for ADAPT-Fraud)\n# Requirements: torch >=1.12, (GPU highly recommended)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:40.861774Z","iopub.execute_input":"2025-09-12T10:07:40.862000Z","iopub.status.idle":"2025-09-12T10:07:40.874007Z","shell.execute_reply.started":"2025-09-12T10:07:40.861980Z","shell.execute_reply":"2025-09-12T10:07:40.873382Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def fourier_time_embed(t, dim, max_freq=10.0):\n    \"\"\"\n    Map scalar timestep t ∈ [0,1] into high-d Fourier features.\n    Args:\n        t: Tensor [B]\n        dim: embedding dimension\n        max_freq: highest frequency for Fourier features\n    Returns:\n        [B, dim]\n    \"\"\"\n    device = t.device\n    half = dim // 2\n    freqs = torch.linspace(1.0, max_freq, half, device=device)\n    angles = t[:, None] * freqs[None, :] * 2 * math.pi\n    emb = torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1)\n    if dim % 2 == 1:  # pad if odd\n        emb = torch.cat([emb, torch.zeros(B, 1, device=device)], dim=-1)\n    return emb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:40.874614Z","iopub.execute_input":"2025-09-12T10:07:40.874800Z","iopub.status.idle":"2025-09-12T10:07:40.891306Z","shell.execute_reply.started":"2025-09-12T10:07:40.874786Z","shell.execute_reply":"2025-09-12T10:07:40.890634Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom typing import List\n\nclass TabDiffusionGenerator(nn.Module):\n    def __init__(\n        self,\n        num_numeric: int,\n        cat_cardinalities: List[int],\n        cond_columns: dict,   # mapping: name -> {\"type\":\"cat\"/\"num\"/\"binary\", \"cardinality\":int (if cat)}\n        token_dim: int = 192,\n        time_embed_dim: int = 128,\n        transformer_layers: int = 4,\n        transformer_heads: int = 4,\n        transformer_ff: int = 512,\n        uncond_prob: float = 0.1\n    ):\n        super().__init__()\n        self.num_num = num_numeric\n        self.cat_cardinalities = cat_cardinalities\n        self.cond_specs = cond_columns         # keep original spec dict\n        self.cond_columns = list(cond_columns.keys())\n        self.token_dim = token_dim\n        self.time_embed_dim = time_embed_dim\n        self.uncond_prob = uncond_prob\n\n        # -------------------------\n        # Input feature embeddings\n        # -------------------------\n        self.num_proj = nn.Linear(1, token_dim)\n        self.cat_embeds = nn.ModuleList([nn.Embedding(card, token_dim) for card in cat_cardinalities])\n\n        # -------------------------\n        # Conditioning embeddings\n        # -------------------------\n        self.cond_embeds = nn.ModuleDict()\n        for col, spec in cond_columns.items():\n            typ = spec.get(\"type\")\n            if typ == \"cat\":\n                card = spec.get(\"cardinality\")\n                if card is None:\n                    raise ValueError(f\"cond_columns must include 'cardinality' for categorical cond {col}\")\n                self.cond_embeds[col] = nn.Embedding(card, token_dim)\n            elif typ == \"num\":\n                self.cond_embeds[col] = nn.Linear(1, token_dim)\n            elif typ == \"binary\":\n                self.cond_embeds[col] = nn.Embedding(2, token_dim)\n            else:\n                raise ValueError(f\"Unknown cond type for {col}: {typ}\")\n\n        # Time embedding\n        self.time_proj = nn.Linear(time_embed_dim, token_dim)\n\n        # Project combined cond -> token\n        cond_in_dim = token_dim * (1 + len(self.cond_embeds))  # time + conds\n        self.cond_proj = nn.Linear(cond_in_dim, token_dim)\n\n        # -------------------------\n        # Transformer backbone\n        # -------------------------\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=token_dim,\n            nhead=transformer_heads,\n            dim_feedforward=transformer_ff,\n            batch_first=True\n        )\n        self.model = nn.TransformerEncoder(encoder_layer, num_layers=transformer_layers)\n\n        # -------------------------\n        # Output projection (embedding space)\n        # -------------------------\n        self.out_proj = nn.Linear(token_dim, token_dim)\n\n        # -------------------------\n        # Decoders for reconstruction\n        # -------------------------\n        self.num_decoders = nn.ModuleList([nn.Linear(token_dim, 1) for _ in range(num_numeric)])\n        self.cat_decoders = nn.ModuleList([nn.Linear(token_dim, card) for card in cat_cardinalities])\n\n    # -----------------------------------------\n    # Build token embeddings from raw inputs\n    # (used for training where we have x_num/x_cat)\n    # -----------------------------------------\n    def _build_tokens_from_inputs(self, x_num, x_cat, cond_token):\n        toks = [cond_token.unsqueeze(1)]  # [B,1,D]\n\n        if x_num is not None and x_num.numel() > 0:\n            num_tokens = []\n            for i in range(self.num_num):\n                feat = x_num[:, i:i+1]               # [B,1]\n                num_tokens.append(self.num_proj(feat.unsqueeze(-1)))  # [B,1,D]\n            toks.append(torch.cat(num_tokens, dim=1))  # [B, num_num, D]\n\n        if x_cat is not None and x_cat.numel() > 0:\n            cat_tokens = []\n            for i, emb in enumerate(self.cat_embeds):\n                cat_tokens.append(emb(x_cat[:, i]))\n            toks.append(torch.stack(cat_tokens, dim=1))  # [B, num_cat, D]\n\n        return torch.cat(toks, dim=1)  # [B, 1 + num_num + num_cat, D]\n\n    # -----------------------------------------\n    # Conditioning token builder (time + conds)\n    # cond_batch entries may be None (we handle it)\n    # -----------------------------------------\n    def _cond_token(self, t, cond_batch, do_cfg_dropout=False):\n        device = t.device\n        B = t.size(0)\n        time_emb = fourier_time_embed(t, self.time_embed_dim)  # expects [B]\n        t_proj = self.time_proj(time_emb)  # [B, D]\n\n        cond_embs = [t_proj]\n        for col, emb_layer in self.cond_embeds.items():\n            val = cond_batch.get(col, None)\n            if val is None:\n                # default zeros (will be sometimes zeroed by classifier-free dropout)\n                if isinstance(emb_layer, nn.Linear):\n                    v = torch.zeros(B, device=device)\n                    cond_embs.append(emb_layer(v.unsqueeze(-1).float()))\n                else:\n                    idx = torch.zeros(B, dtype=torch.long, device=device)\n                    cond_embs.append(emb_layer(idx))\n            else:\n                # ensure on device\n                v = val.to(device)\n                if isinstance(emb_layer, nn.Linear):\n                    cond_embs.append(emb_layer(v.unsqueeze(-1).float()))\n                else:\n                    cond_embs.append(emb_layer(v.long()))\n\n        cond_full = torch.cat(cond_embs, dim=-1)\n        cond_proj = self.cond_proj(cond_full)\n\n        # classifier-free guidance dropout (zero out cond token sometimes)\n        if do_cfg_dropout and torch.rand(1).item() < self.uncond_prob:\n            cond_proj = torch.zeros_like(cond_proj)\n\n        return cond_proj  # [B, D]\n\n    # -----------------------------------------\n    # Training loss: reconstruct numeric + categorical features\n    # -----------------------------------------\n    def training_loss(self, x_num, x_cat, cond_batch):\n        \"\"\"\n        x_num: [B, num_num] (floats, scaled as during training)\n        x_cat: [B, num_cat] (long indices)\n        cond_batch: dict of conditioning tensors (B,) long/float depending on type\n        \"\"\"\n        B = x_num.size(0)\n        device = x_num.device\n        t = torch.rand(B, device=device)  # random time embedding\n\n        cond_token = self._cond_token(t, cond_batch, do_cfg_dropout=True)\n        tokens_clean = self._build_tokens_from_inputs(x_num, x_cat, cond_token)  # [B, seq, D]\n\n        # add noise in embedding space (simple additive noise)\n        noise = torch.randn_like(tokens_clean)\n        tokens_noisy = tokens_clean + noise\n\n        pred = self.model(tokens_noisy)       # [B, seq, D]\n        pred = self.out_proj(pred)            # predicted clean embeddings\n\n        # Decode numeric: each numeric decoder maps token embedding->scalar\n        num_preds = [dec(pred[:, 1 + i]) for i, dec in enumerate(self.num_decoders)]\n        num_preds = torch.cat(num_preds, dim=1)  # [B, num_num]\n        num_loss = F.mse_loss(num_preds, x_num)\n\n        # Decode categorical: cross-entropy per categorical column\n        cat_losses = []\n        offset = 1 + self.num_num\n        for i, dec in enumerate(self.cat_decoders):\n            logits = dec(pred[:, offset + i])   # [B, cardinality]\n            cat_losses.append(F.cross_entropy(logits, x_cat[:, i]))\n        cat_loss = torch.stack(cat_losses).mean() if len(cat_losses) > 0 else torch.tensor(0.0, device=device)\n\n        return num_loss + cat_loss\n\n    # -----------------------------------------\n    # Sampling: produce num_samples conditioned on cond_batch\n    # (iterative denoising in embedding space)\n    # -----------------------------------------\n    @torch.no_grad()\n    def sample(self, num_samples: int, cond_batch: dict, steps: int = 50, cfg_scale: float = 1.5):\n        \"\"\"\n        Returns:\n            x_num_gen: [B, num_num] floats (still in scaler-space if you trained on scaled numerics)\n            x_cat_gen: [B, num_cat] long indices\n        \"\"\"\n        device = next(self.parameters()).device\n        B = num_samples\n        seq_len = 1 + self.num_num + len(self.cat_cardinalities)\n\n        # initialize noisy tokens in embedding space\n        toks = torch.randn(B, seq_len, self.token_dim, device=device)\n\n        for step in reversed(range(steps)):\n            t = torch.full((B,), step / max(1, steps), device=device)\n\n            # compute cond token (with conditioning)\n            cond_proj = self._cond_token(t, cond_batch, do_cfg_dropout=False)\n            # build tokens_in by replacing cond token slot\n            tokens_in = toks.clone()\n            tokens_in[:, 0, :] = cond_proj\n\n            toks_cond = self.out_proj(self.model(tokens_in))\n\n            if cfg_scale != 1.0:\n                # build null (dropped) cond for classifier-free guidance\n                null_cond_proj = self._cond_token(t, cond_batch, do_cfg_dropout=True)\n                tokens_null = toks.clone()\n                tokens_null[:, 0, :] = null_cond_proj\n                toks_null = self.out_proj(self.model(tokens_null))\n                toks_cond = toks_null + cfg_scale * (toks_cond - toks_null)\n\n            # update toks to predicted (simple deterministic) denoised step\n            toks = toks_cond\n\n        # --- decode embeddings back to features ---\n        # numeric outputs\n        num_outs = [dec(toks[:, 1 + i]) for i, dec in enumerate(self.num_decoders)]\n        x_num_gen = torch.cat(num_outs, dim=1)  # [B, num_num]\n\n        # categorical outputs (argmax over logits)\n        cat_outs = []\n        offset = 1 + self.num_num\n        for i, dec in enumerate(self.cat_decoders):\n            logits = dec(toks[:, offset + i])  # [B, cardinality]\n            idx = torch.argmax(logits, dim=-1)  # [B]\n            cat_outs.append(idx)\n        x_cat_gen = torch.stack(cat_outs, dim=1) if len(cat_outs) > 0 else torch.zeros(B, 0, dtype=torch.long, device=device)\n\n        return x_num_gen, x_cat_gen\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:40.891924Z","iopub.execute_input":"2025-09-12T10:07:40.892191Z","iopub.status.idle":"2025-09-12T10:07:40.916254Z","shell.execute_reply.started":"2025-09-12T10:07:40.892146Z","shell.execute_reply":"2025-09-12T10:07:40.915444Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### **Test TabDiffusion with a real benchmark (IEEE-CIS)**","metadata":{}},{"cell_type":"markdown","source":"[The IEEE-CIS data](https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203)\n\n\n**Load the input data**. In this case, we have two datasets: the transaction data and the identity data. \n\nEach row in the transaction data represents attributes of a specific transaction such as money transfer and also other gifting goods and service, like you booked a ticket for others, etc. and captures useful details such as transaction time, amount, payment card information, such as card type, card category, issue bank, country, etc, product or service procured (airtime, data, cable, ticket e.t.c) address, how many addresses are found to be associated with the payment card, distances between billing address, mailing address, zip code, IP address, phone area, etc. purchaser and recipient email domain, days between previous transaction, e.t.c, days between previous transaction, match, such as names on card and address, \n\nEach row in the identity dataset represents identity information such as network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with each transaction. Also, it recorded behavioral fingerprints like account login times/failed to login times, how long an account stayed on the page, etc. \n\nThe transaction_id column is the unique identifier that relates both the transaction and identity tables.","metadata":{}},{"cell_type":"code","source":"# Load datasets\ntransaction = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_transaction.csv\")\nidentity   = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/train_identity.csv\")\nprint(transaction.shape, identity.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:07:40.918505Z","iopub.execute_input":"2025-09-12T10:07:40.918694Z","iopub.status.idle":"2025-09-12T10:08:08.418430Z","shell.execute_reply.started":"2025-09-12T10:07:40.918679Z","shell.execute_reply":"2025-09-12T10:08:08.417775Z"}},"outputs":[{"name":"stdout","text":"(590540, 394) (144233, 41)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# merge datasets\ndf = transaction.merge(identity, on='TransactionID', how='left')\nprint(\"Merged shape:\", df.shape)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:08.419323Z","iopub.execute_input":"2025-09-12T10:08:08.419625Z","iopub.status.idle":"2025-09-12T10:08:09.298041Z","shell.execute_reply.started":"2025-09-12T10:08:08.419599Z","shell.execute_reply":"2025-09-12T10:08:09.297335Z"}},"outputs":[{"name":"stdout","text":"Merged shape: (590540, 434)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n0        2987000        0          86400            68.5         W  13926   \n1        2987001        0          86401            29.0         W   2755   \n2        2987002        0          86469            59.0         W   4663   \n3        2987003        0          86499            50.0         W  18132   \n4        2987004        0          86506            50.0         H   4497   \n\n   card2  card3       card4  card5  ...                id_31  id_32  \\\n0    NaN  150.0    discover  142.0  ...                  NaN    NaN   \n1  404.0  150.0  mastercard  102.0  ...                  NaN    NaN   \n2  490.0  150.0        visa  166.0  ...                  NaN    NaN   \n3  567.0  150.0  mastercard  117.0  ...                  NaN    NaN   \n4  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n\n       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n0        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n1        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n2        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n3        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n4  2220x1080  match_status:2      T     F     T      T      mobile   \n\n                      DeviceInfo  \n0                            NaN  \n1                            NaN  \n2                            NaN  \n3                            NaN  \n4  SAMSUNG SM-G892A Build/NRD90M  \n\n[5 rows x 434 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n      <th>TransactionDT</th>\n      <th>TransactionAmt</th>\n      <th>ProductCD</th>\n      <th>card1</th>\n      <th>card2</th>\n      <th>card3</th>\n      <th>card4</th>\n      <th>card5</th>\n      <th>...</th>\n      <th>id_31</th>\n      <th>id_32</th>\n      <th>id_33</th>\n      <th>id_34</th>\n      <th>id_35</th>\n      <th>id_36</th>\n      <th>id_37</th>\n      <th>id_38</th>\n      <th>DeviceType</th>\n      <th>DeviceInfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2987000</td>\n      <td>0</td>\n      <td>86400</td>\n      <td>68.5</td>\n      <td>W</td>\n      <td>13926</td>\n      <td>NaN</td>\n      <td>150.0</td>\n      <td>discover</td>\n      <td>142.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2987001</td>\n      <td>0</td>\n      <td>86401</td>\n      <td>29.0</td>\n      <td>W</td>\n      <td>2755</td>\n      <td>404.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>102.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2987002</td>\n      <td>0</td>\n      <td>86469</td>\n      <td>59.0</td>\n      <td>W</td>\n      <td>4663</td>\n      <td>490.0</td>\n      <td>150.0</td>\n      <td>visa</td>\n      <td>166.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2987003</td>\n      <td>0</td>\n      <td>86499</td>\n      <td>50.0</td>\n      <td>W</td>\n      <td>18132</td>\n      <td>567.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>117.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2987004</td>\n      <td>0</td>\n      <td>86506</td>\n      <td>50.0</td>\n      <td>H</td>\n      <td>4497</td>\n      <td>514.0</td>\n      <td>150.0</td>\n      <td>mastercard</td>\n      <td>102.0</td>\n      <td>...</td>\n      <td>samsung browser 6.2</td>\n      <td>32.0</td>\n      <td>2220x1080</td>\n      <td>match_status:2</td>\n      <td>T</td>\n      <td>F</td>\n      <td>T</td>\n      <td>T</td>\n      <td>mobile</td>\n      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 434 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"**Preprocess the Dataset** by dropping irrelevant columns, dealing with the missing values, scaling the numerical columns, and encoding the categorical columns","metadata":{}},{"cell_type":"code","source":"# drop identifier columns (we won't model\ndrop_cols = ['TransactionID']  # keep TransactionDT for time_to_detect\ncandidate = df.drop(columns=drop_cols)\n\n# identify label\nlabel_col = 'isFraud'\n\n# numeric / categorical heuristics\nnum_cols = candidate.select_dtypes(include=['int64','float64']).columns.tolist()\nnum_cols = [c for c in num_cols if c != label_col]\ncat_cols = candidate.select_dtypes(include=['object']).columns.tolist()\n\nprint(\"Numeric cols:\", len(num_cols))\nprint(\"Categorical cols:\", len(cat_cols))\n# Optionally prune columns to avoid very high-cardinality ones (or group rare categories)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:09.298805Z","iopub.execute_input":"2025-09-12T10:08:09.299062Z","iopub.status.idle":"2025-09-12T10:08:12.213119Z","shell.execute_reply.started":"2025-09-12T10:08:09.299044Z","shell.execute_reply":"2025-09-12T10:08:12.212487Z"}},"outputs":[{"name":"stdout","text":"Numeric cols: 401\nCategorical cols: 31\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Fill NAs\ndf[num_cols] = df[num_cols].fillna(0.0)\ndf[cat_cols] = df[cat_cols].fillna('NA')\n\n# scalers & encoders\nscaler = StandardScaler()\nscaler.fit(df[num_cols].values)   # save for inference\n\nlabel_encoders = {}\n# cat_cardinalities = []\nfor c in cat_cols:\n    le = LabelEncoder()\n    df[c] = le.fit_transform(df[c].astype(str).values)\n    label_encoders[c] = le\n    # cat_cardinalities.append(len(le.classes_))\n\n# print(\"cat_cardinalities:\", cat_cardinalities[:10])\n# plt.hist(cat_cardinalities)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:12.213786Z","iopub.execute_input":"2025-09-12T10:08:12.213982Z","iopub.status.idle":"2025-09-12T10:08:23.831978Z","shell.execute_reply.started":"2025-09-12T10:08:12.213962Z","shell.execute_reply":"2025-09-12T10:08:23.831401Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"**Define Conditional columns:**\n\nPick and instantiate candidate conditioning variables. These are the categorical features that are mostly useful in depicting the fraud types and provide context to attributes that are associated with certain fraud types, e.g., device used, account type, product type. These columns are fed into the conditional embedding vector (cond_vec), which the diffusion generator uses as side information. This forces the generator to learn distributions conditioned on context, e.g., Fraud patterns when using Device A vs Device B or under different product categories, as against just primarily learning distributions that are fraud against non-fraud. \nThis helps the generator capture multi-modal fraud patterns. It also gives us more control: later, when sampling, we can say, “Generate fraud-like transactions for DeviceType = mobile”, such that the generator will generate different fraud/non-fraud distributions depending on such device type. So in this case, the generator can generate synthetic data of fraudulent samples when the device is \"mobile\" and non-fraudulent samples when the device is also \"mobile\". It is unable to learn this level of representation without conditioning. This is important because fraud is rarely a uniform cluster — it often manifests differently depending on context (e.g., fraud on mobile devices, fraud in online purchases, fraud with high transaction amounts). With only \"isFraud\", the generator has no way to control which type of fraud it’s generating. So these conditioning columns help the generator learn subtypes of fraud (more adversarial realism, but more complexity).","metadata":{}},{"cell_type":"code","source":"# # Choose a handful of columns to form a conditioner (identity/device + product)\n# cond_columns = [\n#     'ProductCD', 'card4', 'card6',\n#     'DeviceType', 'DeviceInfo',\n#     'id_30', 'id_31',\n#     'addr1', 'P_emaildomain', 'R_emaildomain'\n# ]\n# # cond_columns = [c for c in cond_columns if c in df.columns]\n# cond_columns = [c for c in cond_columns if c in cat_cols]\n# print(\"Using conditional columns:\", cond_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:23.832787Z","iopub.execute_input":"2025-09-12T10:08:23.833062Z","iopub.status.idle":"2025-09-12T10:08:23.837025Z","shell.execute_reply.started":"2025-09-12T10:08:23.833039Z","shell.execute_reply":"2025-09-12T10:08:23.836280Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"**Build embedding lookup dictionary module** \n\nCreates an embedding table that stores the embedding of each conditioning variable with shape [n_categories, embedding_dim], where n_categories is the number of labels in each class and embedding_dim is the set embedding dimension (32 in this case); Such that each category (like visa or Windows 10) gets mapped to a learnable 32-dimensional vector and stored in a dictionary keyed by column name that allows us look up the embeddings column by column during the forward pass.\n\n","metadata":{}},{"cell_type":"code","source":"# # Make embedding layers for categorical columns and concatenate\n# CAT_EMBED_DIM = 32\n# cat_cardinalities = {c: int(df[c].nunique()) for c in cat_cols}\n# cat_emb_modules = nn.ModuleDict()\n# for c, card in cat_cardinalities.items():\n#     cat_emb_modules[c] = nn.Embedding(card, CAT_EMBED_DIM)\n# print(\"Built shared cat_emb_modules for\", len(cat_emb_modules), \"categorical columns.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:23.837821Z","iopub.execute_input":"2025-09-12T10:08:23.838069Z","iopub.status.idle":"2025-09-12T10:08:23.854671Z","shell.execute_reply.started":"2025-09-12T10:08:23.838055Z","shell.execute_reply":"2025-09-12T10:08:23.854082Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Dataset - returns numeric features, categorical indices, label, time, account id\nclass IEEECISDatasetTorch(Dataset):\n    def __init__(self, df, num_cols, cat_cols, label_col='isFraud', acct_col='card1', scaler=None):\n        self.df = df.reset_index(drop=True)\n        self.num_cols = num_cols\n        self.cat_cols = cat_cols\n        self.label_col = label_col\n        self.acct_col = acct_col\n        self.scaler = scaler\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        if self.num_cols:\n            x_num = torch.tensor(self.scaler.transform(row[self.num_cols].values.reshape(1,-1)).squeeze(0), dtype=torch.float32)\n        else:\n            x_num = torch.zeros(0, dtype=torch.float32)\n        x_cat = torch.tensor(row[self.cat_cols].astype(int).values, dtype=torch.long) if self.cat_cols else torch.zeros(0, dtype=torch.long)\n        y = torch.tensor(int(row[self.label_col]) if self.label_col in row else 0, dtype=torch.long)\n        tx_time = row['TransactionDT'] if 'TransactionDT' in row else np.nan\n        acct = row[self.acct_col] if self.acct_col in row else None\n        return x_num, x_cat, y, tx_time, acct\n\ndef collate_fn(batch):\n    x_num = torch.stack([b[0] for b in batch], dim=0)\n    x_cat = torch.stack([b[1] for b in batch], dim=0)\n    y = torch.stack([b[2] for b in batch], dim=0)\n    tx_time = [b[3] for b in batch]\n    acct = [b[4] for b in batch]\n    return x_num, x_cat, y, tx_time, acct\n\n# Create DataLoader\ndataset = IEEECISDatasetTorch(df, num_cols, cat_cols, label_col=label_col, acct_col='card1', scaler=scaler)\nloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)\nprint(\"Dataset and loader ready. Dataset size:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:23.855273Z","iopub.execute_input":"2025-09-12T10:08:23.855491Z","iopub.status.idle":"2025-09-12T10:08:26.235980Z","shell.execute_reply.started":"2025-09-12T10:08:23.855470Z","shell.execute_reply":"2025-09-12T10:08:26.235363Z"}},"outputs":[{"name":"stdout","text":"Dataset and loader ready. Dataset size: 590540\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# -------------------------------\n# Conditioning columns (as dict)\n# -------------------------------\nCOND_COLS = {\n    \"isFraud\": {\"type\": \"binary\"},\n}\nfor c in [\"ProductCD\",\"card4\",\"card6\",\"DeviceType\", \"DeviceInfo\",\"id_30\",\"id_31\",\"P_emaildomain\",\"R_emaildomain\"]:\n    COND_COLS[c] = {\"type\": \"cat\", \"cardinality\": len(label_encoders[c].classes_)}\n\n# -------------------------------\n# Build dataset metadata\n# -------------------------------\nFNUM = len(num_cols)\nCAT_CARDINALITIES = [len(label_encoders[c].classes_) for c in cat_cols]\n\n# -------------------------------\n# Device\n# -------------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# -------------------------------\n# Instantiate generator\n# -------------------------------\ngen = TabDiffusionGenerator(\n    num_numeric=FNUM,\n    cat_cardinalities=CAT_CARDINALITIES,\n    cond_columns=COND_COLS,\n    token_dim=192,\n    transformer_layers=4,\n    transformer_heads=4,\n    transformer_ff=512,\n    uncond_prob=0.1\n).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:26.236686Z","iopub.execute_input":"2025-09-12T10:08:26.236864Z","iopub.status.idle":"2025-09-12T10:08:26.563381Z","shell.execute_reply.started":"2025-09-12T10:08:26.236850Z","shell.execute_reply":"2025-09-12T10:08:26.562184Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"## Sample training on one batch\n\n# opt = optim.AdamW(gen.parameters(), lr=2e-4)\n\n# # fetch a batch\n# batch = next(iter(loader))\n# x_num, x_cat, y, tx_time, acct = batch\n\n# x_num = x_num.to(device)\n# x_cat = x_cat.to(device)\n# y = y.to(device).float()\n\n# # --------------------------\n# # Build cond_batch dict\n# # --------------------------\n# cond_batch = {\n#     \"isFraud\": y,  # binary conditioning\n#     \"ProductCD\": x_cat[:, cat_cols.index(\"ProductCD\")],\n#     \"card4\": x_cat[:, cat_cols.index(\"card4\")],\n#     \"card6\": x_cat[:, cat_cols.index(\"card6\")],\n#     \"DeviceType\": x_cat[:, cat_cols.index(\"DeviceType\")],\n#     \"DeviceInfo\": x_cat[:, cat_cols.index(\"DeviceInfo\")],\n#     \"id_30\": x_cat[:, cat_cols.index(\"id_30\")],\n#     \"id_31\": x_cat[:, cat_cols.index(\"id_31\")],\n#     \"P_emaildomain\": x_cat[:, cat_cols.index(\"P_emaildomain\")],\n#     \"R_emaildomain\": x_cat[:, cat_cols.index(\"R_emaildomain\")]\n# }\n\n# # --------------------------\n# # Train step\n# # --------------------------\n# gen.train()\n# loss = gen.training_loss(x_num, x_cat, cond_batch)\n# opt.zero_grad()\n# loss.backward()\n# opt.step()\n\n# print('Smoke step loss:', loss.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:26.564413Z","iopub.execute_input":"2025-09-12T10:08:26.564694Z","iopub.status.idle":"2025-09-12T10:08:26.568516Z","shell.execute_reply.started":"2025-09-12T10:08:26.564671Z","shell.execute_reply":"2025-09-12T10:08:26.567839Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"## Sample training on entire dataset\n\n# opt = optim.AdamW(gen.parameters(), lr=2e-4)\n\n# for step, batch in enumerate(loader):\n#     x_num, x_cat, y, tx_time, acct = batch\n#     x_num, x_cat, y = x_num.to(device), x_cat.to(device), y.to(device).float()\n    \n#     cond_batch = {\n#     \"isFraud\": y,  # binary conditioning\n#     \"ProductCD\": x_cat[:, cat_cols.index(\"ProductCD\")],\n#     \"card4\": x_cat[:, cat_cols.index(\"card4\")],\n#     \"card6\": x_cat[:, cat_cols.index(\"card6\")],\n#     \"DeviceType\": x_cat[:, cat_cols.index(\"DeviceType\")],\n#     \"DeviceInfo\": x_cat[:, cat_cols.index(\"DeviceInfo\")],\n#     \"id_30\": x_cat[:, cat_cols.index(\"id_30\")],\n#     \"id_31\": x_cat[:, cat_cols.index(\"id_31\")],\n#     \"P_emaildomain\": x_cat[:, cat_cols.index(\"P_emaildomain\")],\n#     \"R_emaildomain\": x_cat[:, cat_cols.index(\"R_emaildomain\")]\n# }    \n#     gen.train()\n#     loss = gen.training_loss(x_num, x_cat, cond_batch)\n    \n#     opt.zero_grad()\n#     loss.backward()\n#     opt.step()\n    \n#     if step % 50 == 0:\n#         print(f\"Step {step}, loss = {loss.item():.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-09-12T10:08:26.569414Z","iopub.execute_input":"2025-09-12T10:08:26.569671Z","iopub.status.idle":"2025-09-12T10:08:26.587263Z","shell.execute_reply.started":"2025-09-12T10:08:26.569649Z","shell.execute_reply":"2025-09-12T10:08:26.586625Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def train_generator(\n    gen, train_loader, val_loader, device, \n    epochs=20, lr=2e-4, patience=5, checkpoint_path=\"best_gen.pt\"\n):\n    opt = optim.AdamW(gen.parameters(), lr=lr)\n    \n    # LR scheduler - reduce LR when val loss plateaus\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        opt, mode=\"min\", factor=0.5, patience=2, verbose=True\n    )\n\n    best_val_loss = float(\"inf\")\n    patience_counter = 0\n\n    train_losses = []\n    val_losses = []\n\n    for epoch in range(epochs):\n        # ---- Training ----\n        gen.train()\n        running_loss = []\n        for x_num, x_cat, y, tx_time, acct in train_loader:\n            x_num, x_cat, y = x_num.to(device), x_cat.to(device), y.to(device).float()\n\n            cond_batch = {\n                \"isFraud\": y,\n                \"ProductCD\": x_cat[:, cat_cols.index(\"ProductCD\")],\n                \"card4\": x_cat[:, cat_cols.index(\"card4\")],\n                \"card6\": x_cat[:, cat_cols.index(\"card6\")],\n                \"DeviceType\": x_cat[:, cat_cols.index(\"DeviceType\")],\n                \"DeviceInfo\": x_cat[:, cat_cols.index(\"DeviceInfo\")],\n                \"id_30\": x_cat[:, cat_cols.index(\"id_30\")],\n                \"id_31\": x_cat[:, cat_cols.index(\"id_31\")],\n                \"P_emaildomain\": x_cat[:, cat_cols.index(\"P_emaildomain\")],\n                \"R_emaildomain\": x_cat[:, cat_cols.index(\"R_emaildomain\")]\n            }\n\n            loss = gen.training_loss(x_num, x_cat, cond_batch)\n\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n\n            running_loss.append(loss.item())\n\n        train_loss = np.mean(running_loss)\n        train_losses.append(train_loss)\n\n        # ---- Validation ----\n        gen.eval()\n        val_running = []\n        with torch.no_grad():\n            for x_num, x_cat, y, tx_time, acct in val_loader:\n                x_num, x_cat, y = x_num.to(device), x_cat.to(device), y.to(device).float()\n\n                cond_batch = {\n                    \"isFraud\": y,\n                    \"ProductCD\": x_cat[:, cat_cols.index(\"ProductCD\")],\n                    \"card4\": x_cat[:, cat_cols.index(\"card4\")],\n                    \"card6\": x_cat[:, cat_cols.index(\"card6\")],\n                    \"DeviceType\": x_cat[:, cat_cols.index(\"DeviceType\")],\n                    \"DeviceInfo\": x_cat[:, cat_cols.index(\"DeviceInfo\")],\n                    \"id_30\": x_cat[:, cat_cols.index(\"id_30\")],\n                    \"id_31\": x_cat[:, cat_cols.index(\"id_31\")],\n                    \"P_emaildomain\": x_cat[:, cat_cols.index(\"P_emaildomain\")],\n                    \"R_emaildomain\": x_cat[:, cat_cols.index(\"R_emaildomain\")]\n                }\n\n                val_loss = gen.training_loss(x_num, x_cat, cond_batch)\n                val_running.append(val_loss.item())\n\n        val_loss_epoch = np.mean(val_running)\n        val_losses.append(val_loss_epoch)\n\n        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss_epoch:.4f}\")\n\n        # Step LR scheduler\n        scheduler.step(val_loss_epoch)\n\n        # ---- Checkpointing ----\n        if val_loss_epoch < best_val_loss:\n            best_val_loss = val_loss_epoch\n            patience_counter = 0\n            torch.save(gen.state_dict(), checkpoint_path)\n            print(\"New best model saved.\")\n        else:\n            patience_counter += 1\n\n        # ---- Early Stopping ----\n        if patience_counter >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n    # ---- Load best checkpoint automatically ----\n    print(\"Loading best model from checkpoint...\")\n    gen.load_state_dict(torch.load(checkpoint_path))\n\n    return train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:26.588054Z","iopub.execute_input":"2025-09-12T10:08:26.588237Z","iopub.status.idle":"2025-09-12T10:08:26.606046Z","shell.execute_reply.started":"2025-09-12T10:08:26.588216Z","shell.execute_reply":"2025-09-12T10:08:26.605465Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Plot training and validation losses\ndef plot_train_val_losses(train_losses, val_losses):\n    import matplotlib.pyplot as plt\n    \n    epochs = range(1, len(train_losses) + 1)  # start at 1 instead of 0\n    \n    plt.figure(figsize=(8, 5))\n    plt.plot(epochs, train_losses, label=\"Train Loss\", marker=\"o\")\n    plt.plot(epochs, val_losses, label=\"Validation Loss\", marker=\"o\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training vs Validation Loss\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:26.606752Z","iopub.execute_input":"2025-09-12T10:08:26.607007Z","iopub.status.idle":"2025-09-12T10:08:26.626473Z","shell.execute_reply.started":"2025-09-12T10:08:26.606985Z","shell.execute_reply":"2025-09-12T10:08:26.625736Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Split your dataset into train and validation sets (e.g., 80/20).\nfrom torch.utils.data import random_split\n\nn_total = len(dataset)\nn_train = int(0.8 * n_total)\nn_val = n_total - n_train\ntrain_ds, val_ds = random_split(dataset, [n_train, n_val])\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn)\nval_loader   = DataLoader(val_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:26.627413Z","iopub.execute_input":"2025-09-12T10:08:26.627637Z","iopub.status.idle":"2025-09-12T10:08:26.676537Z","shell.execute_reply.started":"2025-09-12T10:08:26.627613Z","shell.execute_reply":"2025-09-12T10:08:26.675973Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Generator training and validation\ntrain_losses, val_losses = train_generator(\n    gen, train_loader, val_loader, device, epochs=5, patience=7\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T10:08:26.677238Z","iopub.execute_input":"2025-09-12T10:08:26.677490Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# plot training and validation loss\nplot_train_val_losses(train_losses, val_losses)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def sample_synthetic(\n    gen,\n    num_samples: int = 100,\n    cond_overrides: dict = None,\n    steps: int = 50,\n    cfg_scale: float = 1.5,\n    device: str = \"cuda\",\n    scaler = None,\n    num_col_names: list = None,\n    cat_col_names: list = None\n):\n    \"\"\"\n    Sample `num_samples` rows using gen.sample, convert to DataFrame with original headers.\n    - cond_overrides: dict mapping conditioning column -> value (string for cats allowed).\n    - scaler: the StandardScaler used during training (if provided, numeric outputs will be inverse-transformed).\n    - num_col_names, cat_col_names: lists of column names. If None, attempts to use variables `num_cols` and `cat_cols` from global scope.\n    \"\"\"\n    # --- column names fallback to globals if not provided ---\n    if num_col_names is None:\n        try:\n            num_col_names = globals()[\"num_cols\"]\n        except Exception:\n            num_col_names = [f\"num_{i}\" for i in range(gen.num_num)]\n    if cat_col_names is None:\n        try:\n            cat_col_names = globals()[\"cat_cols\"]\n        except Exception:\n            cat_col_names = [f\"cat_{i}\" for i in range(len(gen.cat_cardinalities))]\n\n    # --- build cond_batch shaped (num_samples,) for each cond ---\n    cond_batch = {}\n    cond_overrides = cond_overrides or {}\n\n    for col, spec in gen.cond_specs.items():\n        typ = spec[\"type\"]\n        if col in cond_overrides:\n            val = cond_overrides[col]\n            # categorical: allow string label or integer index\n            if typ == \"cat\":\n                if isinstance(val, str):\n                    # label_encoders must exist for mapping\n                    idx = label_encoders[col].transform([val])[0]\n                    cond_batch[col] = torch.full((num_samples,), idx, dtype=torch.long, device=device)\n                elif isinstance(val, (list, np.ndarray, torch.Tensor)):\n                    arr = np.array(val)\n                    if arr.shape[0] != num_samples:\n                        raise ValueError(f\"cond_overrides[{col}] length must match num_samples or be scalar\")\n                    cond_batch[col] = torch.tensor(arr, dtype=torch.long, device=device)\n                else:\n                    cond_batch[col] = torch.full((num_samples,), int(val), dtype=torch.long, device=device)\n            elif typ == \"binary\":\n                cond_batch[col] = torch.full((num_samples,), int(val), dtype=torch.long, device=device)\n            elif typ == \"num\":\n                cond_batch[col] = torch.full((num_samples,), float(val), dtype=torch.float32, device=device)\n            else:\n                raise ValueError(\"Unknown cond type\")\n        else:\n            # default unconditional filler (zeros). Classifier-free guidance inside sample() can drop conditioning.\n            if typ in (\"cat\", \"binary\"):\n                cond_batch[col] = torch.zeros(num_samples, dtype=torch.long, device=device)\n            else:\n                cond_batch[col] = torch.zeros(num_samples, dtype=torch.float32, device=device)\n\n    # --- sample from generator ---\n    gen_device = next(gen.parameters()).device\n    if device == \"cuda\" and gen_device.type == \"cpu\":\n        # move gen to cuda first if needed or just use gen device\n        device = gen_device.type\n\n    # ensure cond tensors on correct device\n    cond_batch = {k: v.to(gen_device) for k, v in cond_batch.items()}\n\n    x_num_gen, x_cat_gen = gen.sample(num_samples, cond_batch, steps=steps, cfg_scale=cfg_scale)\n\n    # move to cpu / numpy\n    x_num_np = x_num_gen.detach().cpu().numpy()  # [B, num_num]\n    x_cat_np = x_cat_gen.detach().cpu().numpy() if x_cat_gen.numel() > 0 else np.zeros((num_samples, 0), dtype=int)\n\n    # inverse transform numeric if scaler provided\n    if scaler is not None:\n        try:\n            x_num_orig = scaler.inverse_transform(x_num_np)\n        except Exception:\n            # if scaler expects different shape, fall back to raw\n            x_num_orig = x_num_np\n    else:\n        x_num_orig = x_num_np\n\n    # build dataframe\n    df = pd.DataFrame(x_num_orig, columns=num_col_names)\n\n    # decode categorical indices back to original labels using label_encoders\n    for i, col in enumerate(cat_col_names):\n        if x_cat_np.shape[1] > i:\n            idxs = x_cat_np[:, i].astype(int)\n            # label_encoders[col] must exist\n            try:\n                df[col] = label_encoders[col].inverse_transform(idxs)\n            except Exception:\n                # fallback to integer indices if label encoder missing or mismatch\n                df[col] = idxs\n        else:\n            df[col] = np.nan\n\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unconditional batch (all None)\nnum_samples = 100\ncond_batch = {\n    col: torch.zeros(num_samples, dtype=torch.long, device=\"cuda\") \n    for col in gen.cond_columns\n}\nsamples = sample_synthetic(gen, cond_batch, steps=50)\nprint(samples.shape)   # (100, num_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate 100 random samples (unconditional)\nsamples = sample_synthetic(gen, cond_batch, steps=50)\nprint(samples.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T10:44:13.866372Z","iopub.execute_input":"2025-09-10T10:44:13.867118Z","iopub.status.idle":"2025-09-10T10:44:20.833135Z","shell.execute_reply.started":"2025-09-10T10:44:13.867092Z","shell.execute_reply":"2025-09-10T10:44:20.832537Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"torch.Size([100, 433, 192])"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"# Generate 50 fraudulent transactions\nfraud_samples = sample_synthetic(gen, 50, cond_overrides={\"isFraud\": 1})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate 50 non-fraud transactions with ProductCD = \"W\"\nnonfraud_W = sample_synthetic(gen, 50, cond_overrides={\"isFraud\": 0, \"ProductCD\": \"W\"})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T10:43:01.675332Z","iopub.execute_input":"2025-09-10T10:43:01.675860Z","iopub.status.idle":"2025-09-10T10:43:01.693651Z","shell.execute_reply.started":"2025-09-10T10:43:01.675838Z","shell.execute_reply":"2025-09-10T10:43:01.692743Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2353088460.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate 50 non-fraud transactions with ProductCD = \"W\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnonfraud_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_synthetic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_overrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"isFraud\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ProductCD\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"W\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/210800685.py\u001b[0m in \u001b[0;36msample_synthetic\u001b[0;34m(gen, num_samples, cond_overrides, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# try cond_batch as keyword argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx_num_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cat_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# ---- Decode back to dataframe ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: TabDiffusionGenerator.sample() got an unexpected keyword argument 'num_samples'"],"ename":"TypeError","evalue":"TabDiffusionGenerator.sample() got an unexpected keyword argument 'num_samples'","output_type":"error"}],"execution_count":34},{"cell_type":"code","source":"# . Generate 100 samples for multiple categories (e.g., ProductCD ∈ {A, B, C})\nall_samples = []\nfor prod in [\"A\", \"B\", \"C\"]:\n    df_prod = sample_synthetic(gen, 30, cond_overrides={\"ProductCD\": prod})\n    all_samples.append(df_prod)\n\nall_samples = pd.concat(all_samples, ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Generate 20 fraud samples where DeviceType = \"web\"\nfraud_web = sample_synthetic(gen, 20, cond_overrides={\"isFraud\": 1, \"DeviceType\": \"web\"})","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}