{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **ADAPT-G: Adversarial Diffusion And Probabilistic Transformer-Graph for Financial Fraud Detection**\n\n---\n\n## Overview\n\n**ADAPT-G** is a novel hybrid architecture designed for **financial transaction and mobile money fraud detection**.  \nIt combines **adversarial curriculum learning with a diffusion-based generator** to create realistic synthetic fraud scenarios and a **probabilistic Transformer-Graph Neural Network (GNN) detector** to identify both **behavioral** (temporal) and **structural** (relational) anomalies.\n\nOur goal is to **push the boundaries of fraud detection** by addressing the weaknesses of traditional models in catching **stealthy, low-signal fraud patterns** — particularly those that exploit the **network relationships** between entities and **temporal transaction patterns**.\n\n---\n\n## Research Goals\n\n- **Develop** a hybrid adversarial architecture capable of detecting complex fraud signals in transaction networks.\n- **Incorporate** probabilistic reasoning into the detection stage for better uncertainty estimation and high-risk flagging.\n- **Benchmark** against state-of-the-art fraud detection models on real-world financial datasets.\n- **Evaluate** across both temporal and graph-based perspectives to capture full fraud signatures.\n\n---\n\n## Model Architecture\n\nThe **ADAPT-G** framework has two major components:\n\n1. **Diffusion-based Generator**  \n   - Generates high-quality, diverse fraudulent transaction sequences and relational patterns.  \n   - Uses **adversarial curriculum learning** to gradually create harder-to-detect fraudulent scenarios.\n\n2. **Probabilistic Transformer-GNN Detector**  \n   - **Transformer**: Models per-entity temporal transaction behavior.\n   - **Lightweight GNN**: Captures graph-level relational dependencies between entities (accounts, devices, merchants).  \n   - **Probabilistic Output Layer**: Produces calibrated uncertainty scores alongside classification outputs.\n\n---\n\n## Benchmark Models\n\nWe will compare ADAPT-G against:\n\n- **XGBoost** (tabular, feature-engineered baseline)\n- **GCN** (Graph Convolutional Network)\n- **GAT** (Graph Attention Network)\n- **Temporal GNNs** (TGAT, TGN)\n- **LSTM/GRU Autoencoders** (temporal anomaly detection baselines)\n- **TabTransformer** (tabular deep learning baseline)\n\n---\n\n## Datasets\n\nWe will evaluate on **multiple benchmark datasets** for financial/mobile money fraud detection:\n\n- **IEEE-CIS Fraud Detection** (Kaggle)\n- **PaySim** (Mobile money fraud simulation)\n- **Elliptic Dataset** (Bitcoin transaction fraud/illicit activity)\n- **SIMF Dataset** (Mobile money & transaction fraud – simulated and real-world mix)\n\nEach dataset will be preprocessed into both **tabular** and **graph-structured formats** where applicable, ensuring fair comparison across all models.\n","metadata":{}},{"cell_type":"markdown","source":"## **2. Imports & Utilities**\n\n---\n\nThis section loads all **core libraries** required for the ADAPT-G framework and defines key **utility functions** for:\n\n1. **Seeding for reproducibility** — Ensures consistent experimental results.\n2. **Metric calculations** — Precision, Recall, F1-score, AUC-ROC, and more.\n3. **Visualization** — For training/evaluation curves, ROC plots, and confusion matrices.\n","metadata":{}},{"cell_type":"code","source":"# # Install required packages\n# !pip install torch torchvision torch_geometric transformers diffusers scikit-learn pandas matplotlib seaborn tqdm","metadata":{"execution":{"iopub.status.busy":"2025-08-12T22:06:30.660415Z","iopub.execute_input":"2025-08-12T22:06:30.660978Z","iopub.status.idle":"2025-08-12T22:08:16.280825Z","shell.execute_reply.started":"2025-08-12T22:06:30.660946Z","shell.execute_reply":"2025-08-12T22:08:16.279438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Imports\n# ================================\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import (\n    precision_score, recall_score, f1_score,\n    roc_auc_score, roc_curve, confusion_matrix,\n    accuracy_score\n)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch_geometric\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv, GATConv, global_mean_pool\nfrom datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T22:10:10.422229Z","iopub.execute_input":"2025-08-12T22:10:10.422660Z","iopub.status.idle":"2025-08-12T22:10:23.921215Z","shell.execute_reply.started":"2025-08-12T22:10:10.422624Z","shell.execute_reply":"2025-08-12T22:10:23.920444Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ================================\n# Helper Functions\n# ================================\n\ndef set_seed(seed: int = 42):\n    \"\"\"\n    Sets seed for reproducibility across Python, NumPy, and PyTorch.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    print(f\"[INFO] Seed set to: {seed}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T22:10:32.444968Z","iopub.execute_input":"2025-08-12T22:10:32.445565Z","iopub.status.idle":"2025-08-12T22:10:32.451502Z","shell.execute_reply.started":"2025-08-12T22:10:32.445537Z","shell.execute_reply":"2025-08-12T22:10:32.450461Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# -------------------------------------------------\n# Metrics\n# -------------------------------------------------\ndef calculate_metrics(y_true, y_pred, y_prob=None):\n    \"\"\"\n    Calculate core classification metrics.\n    y_true: Ground truth labels\n    y_pred: Predicted labels\n    y_prob: Predicted probabilities (for ROC/AUC)\n    \"\"\"\n    metrics_dict = {\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n        \"F1\": f1_score(y_true, y_pred, zero_division=0)\n    }\n    if y_prob is not None:\n        metrics_dict[\"AUC-ROC\"] = roc_auc_score(y_true, y_prob)\n    return metrics_dict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T22:10:44.603128Z","iopub.execute_input":"2025-08-12T22:10:44.603501Z","iopub.status.idle":"2025-08-12T22:10:44.609672Z","shell.execute_reply.started":"2025-08-12T22:10:44.603475Z","shell.execute_reply":"2025-08-12T22:10:44.608770Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# -------------------------------------------------\n# Visualization Utilities\n# -------------------------------------------------\ndef plot_loss_curves(train_losses, val_losses):\n    plt.figure(figsize=(8, 5))\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training & Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_roc_curve(y_true, y_prob):\n    fpr, tpr, _ = roc_curve(y_true, y_prob)\n    auc_score = roc_auc_score(y_true, y_prob)\n    plt.figure(figsize=(6, 6))\n    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.3f}')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, labels=None):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(5, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T22:11:00.356091Z","iopub.execute_input":"2025-08-12T22:11:00.356448Z","iopub.status.idle":"2025-08-12T22:11:00.365081Z","shell.execute_reply.started":"2025-08-12T22:11:00.356419Z","shell.execute_reply":"2025-08-12T22:11:00.364103Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## **3. Model Architecture**\n\nThis section defines the two core components of ADAPT-Fraud:\n\n- **3.1 Generator — Adversarial Diffusion Anomaly Simulator**  \n  A conditional diffusion (DDPM-style) generator that synthesizes realistic transaction sequences / mini-graphs. It can be conditioned on context (merchant, device, account profile). The generator will be used in an *adversarial curriculum*: it tries to produce fraud samples that are realistic and hard for the detector to flag.\n\n- **3.2 Detector — Probabilistic Transformer-GNN**  \n  A hybrid detector composed of:\n    - a lightweight **GNN encoder** for graph-structural features (e.g., account–device–merchant links),\n    - a **Transformer encoder** for per-entity transaction sequences,\n    - a **fusion layer** that merges temporal + structural embeddings,\n    - a **probabilistic output** implemented via MC Dropout (fast, practical uncertainty) producing both a fraud score and an uncertainty estimate.\n\nBelow are prototype implementations.\n","metadata":{}},{"cell_type":"markdown","source":"### **3.1 Generator: DDPM-style Diffusion**","metadata":{}},{"cell_type":"code","source":"# --------------------\n# Utilities for DDPM\n# --------------------\nclass TimeEmbedding(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n        self.linear1 = nn.Linear(dim, dim*4)\n        self.act = nn.GELU()\n        self.linear2 = nn.Linear(dim*4, dim)\n\n    def forward(self, t: torch.Tensor):\n        # t: (B,) long tensor timesteps\n        half = self.dim // 2\n        emb = torch.log(10000) / (half - 1)\n        emb = torch.exp(torch.arange(half, device=t.device) * -emb)\n        emb = t.float().unsqueeze(1) * emb.unsqueeze(0)  # (B, half)\n        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n        emb = self.act(self.linear1(emb))\n        emb = self.linear2(emb)\n        return emb  # (B, dim)\n\nclass TransformerDenoiser(nn.Module):\n    \"\"\"\n    Transformer-based denoiser operating on (B, seq_len, feat_dim).\n    Optionally accepts a conditioning vector (B, cond_dim) that is broadcast to seq_len as extra tokens.\n    \"\"\"\n    def __init__(self, feat_dim, emb_dim=128, n_heads=4, n_layers=4, cond_dim=0, dropout=0.1, max_seq_len=128):\n        super().__init__()\n        self.emb = nn.Linear(feat_dim, emb_dim)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=emb_dim*4, dropout=dropout, activation='gelu')\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n        self.time_mlp = TimeEmbedding(emb_dim)\n        self.pos_embed = nn.Parameter(self._positional_encoding(max_seq_len, emb_dim), requires_grad=False)\n        self.out = nn.Linear(emb_dim, feat_dim)\n        self.cond_proj = nn.Linear(cond_dim, emb_dim) if cond_dim > 0 else None\n        self.dropout = nn.Dropout(dropout)\n        self.max_seq_len = max_seq_len\n\n    def _positional_encoding(self, max_len, d_model):\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        return pe.unsqueeze(0)  # (1, max_len, d_model)\n\n    def forward(self, x, t, cond=None, src_key_padding_mask=None):\n        # x: (B, seq_len, feat_dim) (noisy input)\n        B, L, F = x.shape\n        assert L <= self.max_seq_len, \"Increase max_seq_len\"\n        h = self.emb(x) + self.pos_embed[:, :L, :].to(x.device)\n        t_emb = self.time_mlp(t)[:, None, :]  # (B, 1, emb_dim)\n        h = h + t_emb  # add timestep embedding broadcast\n        if cond is not None and self.cond_proj is not None:\n            # cond: (B, cond_dim) -> project and add per-token\n            cond_p = self.cond_proj(cond)[:, None, :]  # (B,1,emb)\n            h = h + cond_p\n        # transformer expects (L, B, emb)\n        h = h.permute(1, 0, 2)\n        h = self.transformer(h, src_key_padding_mask=src_key_padding_mask)\n        h = h.permute(1, 0, 2)\n        out = self.out(self.dropout(h))\n        return out  # predicted denoised noise or reconstructed features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --------------------\n#  DDPM Class\n# --------------------\nclass DDPMGenerator(nn.Module):\n    \"\"\"\n    Robust DDPM-like generator wrapper using TransformerDenoiser.\n    Implements standard forward q-sampling and a training loss p_losses that predicts noise.\n    \"\"\"\n    def __init__(self, seq_len, feat_dim, timesteps=100, cond_dim=0, denoiser_params=None):\n        super().__init__()\n        self.seq_len = seq_len\n        self.feat_dim = feat_dim\n        self.input_shape = (seq_len, feat_dim)\n        self.timesteps = timesteps\n        self.betas = torch.linspace(1e-4, 2e-2, timesteps).to(device)\n        self.alphas = 1.0 - self.betas\n        self.alpha_bar = torch.cumprod(self.alphas, dim=0)\n        denoiser_params = denoiser_params or {}\n        self.denoiser = TransformerDenoiser(feat_dim, cond_dim=cond_dim, **denoiser_params).to(device)\n\n    def q_sample(self, x0, t, noise=None):\n        # x0: (B, L, F), t: (B,) long\n        if noise is None:\n            noise = torch.randn_like(x0)\n        # gather alpha_bar per t\n        alpha_bar_t = self.alpha_bar[t].view(-1, 1, 1).to(x0.device)\n        return torch.sqrt(alpha_bar_t) * x0 + torch.sqrt(1 - alpha_bar_t) * noise\n\n    def p_losses(self, x0, t, cond=None, src_key_padding_mask=None):\n        B = x0.shape[0]\n        noise = torch.randn_like(x0)\n        x_t = self.q_sample(x0, t, noise=noise)\n        # predict noise\n        pred = self.denoiser(x_t, t, cond=cond, src_key_padding_mask=src_key_padding_mask)\n        loss = F.mse_loss(pred, noise)\n        return loss\n\n    def sample(self, batch_size, cond=None, device=device, guidance_scale=0.0):\n        \"\"\"\n        Ancestral sampling loop (simplified). guidance_scale unused here but left for classifier guidance extension.\n        Returns (B, L, F) generated sequences.\n        \"\"\"\n        x_t = torch.randn(batch_size, self.seq_len, self.feat_dim, device=device)\n        for step in reversed(range(self.timesteps)):\n            t = torch.full((batch_size,), step, device=device, dtype=torch.long)\n            # predict noise\n            eps_theta = self.denoiser(x_t, t, cond=cond)\n            alpha = self.alphas[step]\n            alpha_bar = self.alpha_bar[step]\n            beta = self.betas[step]\n            coef1 = 1 / math.sqrt(alpha)\n            coef2 = (beta / (1 - alpha_bar)) ** 0.5\n            x_t = coef1 * (x_t - (beta / math.sqrt(1 - alpha_bar)) * eps_theta)\n            if step > 0:\n                x_t = x_t + coef2 * torch.randn_like(x_t)\n        return x_t\n    \n    def ddim_sample(generator: DDPMGeneratorRobust, batch_size, cond=None, eta=0.0, device=device, timesteps=None, classifier=None, guidance_scale=0.0):\n        \"\"\"\n        DDIM sampler (deterministic style) with optional classifier guidance.\n        - generator: DDPMGeneratorRobust instance (must expose alphas, alpha_bar, denoiser)\n        - classifier: function f(x) -> scalar logit tensor (B,) or class logits (B,num_classes)\n          If provided and guidance_scale > 0, we compute grad log p(y_target|x) w.r.t x and adjust sampling.\n          classifier must be PyTorch and return logits with requires_grad enabled.\n        - eta: stochasticity control (0 => deterministic DDIM).\n        - guidance_scale: positive scalar to scale gradient used for guidance.\n        Returns: generated sequences (B, L, F)\n        \"\"\"\n        generator.denoiser.eval()\n        timesteps = timesteps if timesteps is not None else generator.timesteps\n        device = next(generator.parameters()).device\n        seq_len = generator.seq_len; feat_dim = generator.feat_dim\n    \n        # choose ddim steps (we use generator.timesteps discrete steps but could subsample)\n        steps = list(range(0, generator.timesteps, max(1, generator.timesteps//timesteps)))\n        if steps[-1] != generator.timesteps-1:\n            steps.append(generator.timesteps-1)\n    \n        # prepare x_T\n        x_t = torch.randn(batch_size, seq_len, feat_dim, device=device)\n    \n        for i in reversed(range(len(steps))):\n            step = steps[i]\n            t = torch.full((batch_size,), step, dtype=torch.long, device=device)\n            with torch.enable_grad():\n                x_t.requires_grad_(True)\n                eps = generator.denoiser(x_t, t, cond=cond)  # predicted noise\n                # optional classifier guidance: compute gradient of logit w.r.t x_t\n                if (classifier is not None) and (guidance_scale > 0.0):\n                    logits = classifier(x_t)  # expect shape (B,) or (B, num_classes) - choose a scalar objective\n                    # If classifier returns multi-class logits, select fraud logit (class index 1)\n                    if logits.dim() > 1:\n                        target_logit = logits[:,1]  # make sure classifier has second dim representing fraud\n                    else:\n                        target_logit = logits\n                    # compute gradient of target_logit w.r.t x_t\n                    grads = torch.autograd.grad(outputs=target_logit.sum(), inputs=x_t, retain_graph=False, create_graph=False)[0]  # (B, L, F)\n                    # normalize gradient and apply as guidance on eps (empirical)\n                    grads = grads / (grads.view(batch_size, -1).norm(dim=1).view(batch_size,1,1) + 1e-8)\n                    # move eps in direction that increases logit (or decreases detection probability depending objective)\n                    # if we want generator to **fool** detector (make detector think benign), we should reduce classifier fraud logit\n                    # so we move x_t in -grad direction; adjust eps accordingly\n                    eps = eps - guidance_scale * grads\n    \n                # standard ddim update:\n                alpha_t = generator.alpha_bar[step].to(device)\n                if i == 0:\n                    prev_alpha = torch.tensor(1.0, device=device)\n                else:\n                    prev_alpha = generator.alpha_bar[steps[i-1]].to(device)\n                # compute pred x0\n                x0_pred = (x_t - torch.sqrt(1 - alpha_t) * eps) / (torch.sqrt(alpha_t) + 1e-8)\n                # compute direction pointing to x_t\n                dir_xt = torch.sqrt(1 - prev_alpha) * eps\n                x_prev = torch.sqrt(prev_alpha) * x0_pred + dir_xt\n                # add noise if eta > 0\n                if eta > 0 and i > 0:\n                    sigma = eta * torch.sqrt((1 - prev_alpha) / (1 - alpha_t)) * torch.sqrt(1 - alpha_t / prev_alpha)\n                    x_prev = x_prev + sigma * torch.randn_like(x_prev)\n                x_t = x_prev.detach()\n                x_t.requires_grad_(False)\n        return x_t.detach()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **3.2 Detector: Probabilistic Transformer-GNN**","metadata":{}},{"cell_type":"code","source":"# --------------------\n# GNN Encoder (lightweight)\n# --------------------\nclass GraphEncoder(nn.Module):\n    \"\"\"\n    Simple GAT-based encoder that produces node-level embeddings and a graph-level embedding.\n    For transaction fraud, nodes can be accounts; edges can be transactions (optionally temporal).\n    \"\"\"\n    def __init__(self, in_channels, hidden_channels=64, out_channels=128, heads=2, dropout=0.2):\n        super().__init__()\n        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n        self.pool = global_mean_pool\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, x, edge_index, batch_idx):\n        x = F.elu(self.conv1(x, edge_index))\n        x = self.dropout(x)\n        x = F.elu(self.conv2(x, edge_index))\n        g_emb = self.pool(x, batch_idx)\n        return x, g_emb  # node embeddings, graph-level embedding","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --------------------\n# Transformer Encoder for sequences\n# --------------------\nclass TemporalTransformer(nn.Module):\n    \"\"\"\n    Transformer encoder for per-entity transaction sequences.\n    Accepts padded sequences (B, seq_len, feat_dim)\n    Returns per-entity embedding (B, emb_dim)\n    \"\"\"\n     def __init__(self, feat_dim, emb_dim=128, n_heads=4, n_layers=3, dropout=0.1, max_seq_len=128):\n        super().__init__()\n        self.emb = nn.Linear(feat_dim, emb_dim)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads, dim_feedforward=emb_dim*4, dropout=dropout, activation='gelu')\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n        self.pos_embed = nn.Parameter(self._positional_encoding(max_seq_len, emb_dim), requires_grad=False)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n    def _positional_encoding(self, max_len, d_model):\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        return pe.unsqueeze(0)\n    def forward(self, seq_x, src_key_padding_mask=None):\n        B, L, F = seq_x.shape\n        x = self.emb(seq_x) + self.pos_embed[:, :L, :].to(seq_x.device)\n        x = x.permute(1, 0, 2)\n        x = self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n        x = x.permute(1, 0, 2)\n        x = x.permute(0, 2, 1)\n        x = self.pool(x).squeeze(-1)\n        return x  # (B, emb_dim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --------------------\n# Fusion + Probabilistic Output\n# --------------------\nclass ProbabilisticFusionDetector(nn.Module):\n    \"\"\"\n    Combines graph-level embedding and transformer entity embedding.\n    Outputs a fraud logit and supports MC Dropout for uncertainty estimation.\n    \"\"\"\n    def __init__(self, gnn_out_dim, trans_out_dim, hidden_dim=256, dropout=0.3, mc_runs=8):\n        super().__init__()\n        self.g_proj = nn.Linear(gnn_out_dim, hidden_dim)\n        self.t_proj = nn.Linear(trans_out_dim, hidden_dim)\n        self.fusion = nn.Sequential(\n            nn.Linear(hidden_dim*2, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim//2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n        )\n        self.classifier = nn.Linear(hidden_dim//2, 1)\n        self.mc_runs = mc_runs\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, g_emb, t_emb):\n        g_p = F.relu(self.g_proj(g_emb))\n        t_p = F.relu(self.t_proj(t_emb))\n        x = torch.cat([g_p, t_p], dim=1)\n        x = self.fusion(x)\n        logit = self.classifier(x).squeeze(-1)\n        prob = torch.sigmoid(logit)\n        return prob, logit\n\n    def mc_predict(self, g_emb, t_emb):\n        # Monte-Carlo dropout predictive mean and std\n        self.train()\n        probs = []\n        for _ in range(self.mc_runs):\n            p, _ = self.forward(g_emb, t_emb)\n            probs.append(p.unsqueeze(0))\n        probs = torch.cat(probs, dim=0)\n        mean_p = probs.mean(dim=0)\n        std_p = probs.std(dim=0)\n        return mean_p, std_p\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Helper: mapping generated sequences into detector inputs\n# ================================\ndef build_graph_from_transactions(batch_transactions):\n    \"\"\"\n    Placeholder: convert a batch of generated transactions (B, seq_len, feat_dim)\n    into a torch_geometric Batch (nodes, edges, node_features, batch mapping).\n    For prototyping:\n      - treat each generated sequence as a small ego-graph where the central node is the account,\n        and edges represent transactions to merchant/device nodes (synthetic).\n      - node features can be derived from summary stats of sequences.\n    Implement proper entity mapping when using real datasets.\n    \"\"\"\n    geo_data_list = []\n    for i, seq in enumerate(batch_transactions):\n        # seq: (seq_len, feat_dim)\n        # simple synthetic graph: nodes = [account node, merchant nodes for each tx]\n        seq = seq.detach().cpu().numpy()\n        seq_len = seq.shape[0]\n        # Node features: account summary + merchant features per tx (dummy)\n        # account node feature = mean over seq features\n        account_feat = seq.mean(axis=0)\n        merchant_feats = seq  # treat each tx as a merchant node feature (simplified)\n        node_feats = np.vstack([account_feat[None, :], merchant_feats])  # (seq_len+1, feat_dim)\n        x = torch.tensor(node_feats, dtype=torch.float)\n        # edges: from account (0) to each merchant node (1..L)\n        src = [0]*seq_len\n        dst = list(range(1, seq_len+1))\n        edge_index = torch.tensor([src + dst, dst + src], dtype=torch.long)  # make bidirectional\n        batch_idx = torch.zeros(x.size(0), dtype=torch.long)  # single-graph batch idx\n        geo = GeometricData(x=x, edge_index=edge_index)\n        geo.batch = batch_idx\n        geo_data_list.append(geo)\n    batch = GeometricBatch.from_data_list(geo_data_list)\n    return batch\n\ndef seq_to_transformer_input(generated_seq):\n    \"\"\"\n    generated_seq: (B, L, F) tensor\n    return: seq tensor same shape, and optional key padding mask (if variable length)\n    \"\"\"\n    # For prototype assume fixed seq_len and no padding mask\n    return generated_seq, None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Loss & adversarial objectives\n# ================================\nbce = nn.BCELoss()\n\ndef detector_loss_fn(pred_prob, y_true):\n    return bce(pred_prob, y_true.float())\n\nEPS = 1e-8\ndef generator_adv_loss_from_detector(detector_model, g_emb, t_emb):\n    \"\"\"\n    Generator wants to minimize detectability. If detector outputs mean probability p, generator loss:\n      adv_loss = - mean( log(1 - p + eps) )\n    This encourages p -> 0 for generated fraud (detector should think it's benign).\n    \"\"\"\n    with torch.no_grad():\n        p, _ = detector_model.forward(g_emb, t_emb)\n    # Note: generator should backprop through detector (no .detach()) if doing end-to-end adversarial training.\n    # For stability, we compute adv loss with gradient through p.\n    p_for_grad, _ = detector_model.forward(g_emb, t_emb)\n    adv_loss = -torch.log(1 - p_for_grad + EPS).mean()\n    return adv_loss\n\nclass CurriculumScheduler:\n    \"\"\"\n    Scheduler that adjusts a 'difficulty' scalar in [0,1] representing how close generated samples are to normal.\n    For example, difficulty=0 => generate far-novel; difficulty=1 => generate near-normal (harder).\n    Increase difficulty over time as detector improves.\n    \"\"\"\n    def __init__(self, start=0.2, end=0.95, steps=10000):\n        self.start = start\n        self.end = end\n        self.steps = steps\n        self.current_step = 0\n    def step(self):\n        self.current_step += 1\n        frac = min(1.0, self.current_step / self.steps)\n        return self.start + frac * (self.end - self.start)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Adversarial training loop**\n\nWe train in alternating steps:\n\n1. **Pretrain detector** on real data (legitimate + known fraud) for a few epochs.\n2. Loop:\n   - **Generator step**: sample noise and context → generate fraud examples → compute generator losses:\n       - diffusion denoising loss (reconstruction/denoising)\n       - adversarial loss: generator is rewarded for producing samples that the detector labels as *non-fraud* (i.e., low fraud probability)\n       - combined loss = denoising_loss + lambda_adv * adversarial_loss\n       - update generator\n   - **Detector step**: train detector on a mixed batch (real legit, real fraud if available, generated fraud) with detector_loss; optionally upweight generated fraud to harden detector; update detector.\n3. Increase generator difficulty periodically via curriculum scheduler (e.g., sample generation closer to normal).\n","metadata":{}},{"cell_type":"code","source":"# ================================\n# Adversarial training loop \n# ================================\ndef train_adversarial(generator: DDPMGeneratorRobust,\n                      detector_gnn: GraphEncoderGAT,\n                      detector_trans: TemporalTransformerEncoder,\n                      fusion_detector: FusionProbabilisticDetector,\n                      data_loader_real: DataLoader,\n                      epochs=10,\n                      gen_steps_per_epoch=1,\n                      det_steps_per_epoch=1,\n                      adv_lambda=1.0,\n                      curriculum_steps=10000,\n                      save_dir=\"checkpoints\"):\n    os.makedirs(save_dir, exist_ok=True)\n    # optimizers\n    opt_g = optim.Adam(generator.parameters(), lr=2e-4)\n    opt_d = optim.Adam(list(detector_gnn.parameters()) + list(detector_trans.parameters()) + list(fusion_detector.parameters()), lr=1e-4)\n    scheduler = CurriculumScheduler(start=0.2, end=0.95, steps=curriculum_steps)\n    global_step = 0\n\n    for epoch in range(epochs):\n        for real_batch in data_loader_real:\n            # Unpack real batch - TODO: adapt to your dataset loader\n            # Expect real_batch to provide:\n            # seq_real: (B, L, F), cond_vec: (B, cond_dim) optional, y_real: (B,), graph_real: geo batch\n            seq_real, cond_vec, y_real, geo_real = real_batch\n            seq_real = seq_real.to(device); y_real = y_real.to(device)\n            cond_vec = cond_vec.to(device) if cond_vec is not None else None\n\n            # ------------------\n            # Generator steps\n            # ------------------\n            for _ in range(gen_steps_per_epoch):\n                generator.train()\n                # sample random timesteps for q\n                t = torch.randint(0, generator.timesteps, (seq_real.size(0),), device=device)\n                denoise_loss = generator.p_losses(seq_real, t, cond=cond_vec)\n                # sample generated sequences conditioned on cond_vec and current curriculum difficulty\n                difficulty = scheduler.step()\n                # one way to condition difficulty: scale noise during sampling or mix generated with real samples\n                x_fake = generator.sample(seq_real.size(0), cond=cond_vec, device=device)\n                # map generated seq to detector inputs\n                seq_fake, mask_fake = seq_to_transformer_input(x_fake)\n                geo_fake = build_graph_from_transactions(x_fake)  # GeometricBatch\n                # compute detector embeddings (requires detector in train mode)\n                detector_gnn.eval(); detector_trans.eval(); fusion_detector.eval()\n                # compute g_emb and t_emb but keep computational graph for generator adv loss (we want gradients to flow into generator, not detectors)\n                # If you want pure adversarial generator updating, run detector in eval but with grad enabled:\n                for p in detector_gnn.parameters(): p.requires_grad = False\n                for p in detector_trans.parameters(): p.requires_grad = False\n                for p in fusion_detector.parameters(): p.requires_grad = False\n\n                # prepare geometric inputs\n                geo_fake = geo_fake.to(device)\n                node_x = geo_fake.x.to(device)\n                edge_index = geo_fake.edge_index.to(device)\n                batch_idx = geo_fake.batch.to(device)\n                _, g_emb_fake = detector_gnn(node_x, edge_index, batch_idx)\n\n                t_emb_fake = detector_trans(seq_fake.to(device), src_key_padding_mask=mask_fake)\n                # Now compute adversarial loss using detector forward (but detectors frozen)\n                # we want gradients w.r.t generator parameters -> ensure p depends on generator output\n                fusion_detector.train()\n                adv_loss = -torch.log(1 - fusion_detector.forward(g_emb_fake, t_emb_fake)[0] + 1e-8).mean()\n\n                gen_loss = denoise_loss + adv_lambda * adv_loss\n\n                opt_g.zero_grad()\n                gen_loss.backward()\n                opt_g.step()\n\n                # re-enable detector grads\n                for p in detector_gnn.parameters(): p.requires_grad = True\n                for p in detector_trans.parameters(): p.requires_grad = True\n                for p in fusion_detector.parameters(): p.requires_grad = True\n\n            # ------------------\n            # Detector steps\n            # ------------------\n            for _ in range(det_steps_per_epoch):\n                fusion_detector.train(); detector_gnn.train(); detector_trans.train()\n                # Build mixed dataset: real legit + real fraud + generated fraud (optionally)\n                # For simplicity: combine seq_real + x_fake and corresponding geo batches\n                x_fake = x_fake.detach()\n                seq_mixed = torch.cat([seq_real, x_fake], dim=0)\n                y_fake = torch.ones(seq_real.size(0), dtype=torch.float, device=device)  # label generated as fraud (1)\n                y_mixed = torch.cat([y_real, y_fake], dim=0)\n\n                # Build graph batch for mixed\n                geo_real = geo_real.to(device)\n                geo_fake = build_graph_from_transactions(x_fake).to(device)\n                geo_mixed = GeometricBatch.from_data_list(list(geo_real.to_data_list()) + list(geo_fake.to_data_list())).to(device)\n\n                # transformer inputs\n                seq_mixed_t, mask_mixed = seq_to_transformer_input(seq_mixed)\n\n                # detector forward\n                node_x = geo_mixed.x.to(device)\n                edge_idx = geo_mixed.edge_index.to(device)\n                batch_idx = geo_mixed.batch.to(device)\n                _, g_emb_mixed = detector_gnn(node_x, edge_idx, batch_idx)\n                t_emb_mixed = detector_trans(seq_mixed_t.to(device), src_key_padding_mask=mask_mixed)\n                # Note: g_emb_mixed corresponds to graph-level embeddings for each graph in batch (size = B_mixed)\n                # however depending on batching, you may need to align graph embeddings to sequence order; ensure loader building matches this order.\n\n                preds, logits = fusion_detector(g_emb_mixed, t_emb_mixed)\n                det_loss = detector_loss_fn(preds, y_mixed)\n\n                opt_d.zero_grad()\n                det_loss.backward()\n                opt_d.step()\n\n            # --------------------\n            # Logging, checkpoint\n            # --------------------\n            global_step += 1\n            if global_step % 50 == 0:\n                print(f\"[Epoch {epoch}] Step {global_step}: gen_loss={gen_loss.item():.4f}, det_loss={det_loss.item():.4f}, difficulty={difficulty:.3f}\")\n\n            if global_step % 500 == 0:\n                # save checkpoint\n                torch.save({\n                    'generator_state': generator.state_dict(),\n                    'detector_gnn': detector_gnn.state_dict(),\n                    'detector_trans': detector_trans.state_dict(),\n                    'fusion_detector': fusion_detector.state_dict(),\n                    'opt_g': opt_g.state_dict(),\n                    'opt_d': opt_d.state_dict(),\n                    'global_step': global_step\n                }, os.path.join(save_dir, f\"checkpoint_step_{global_step}.pt\"))\n\n        # End epoch\n    print(\"Adversarial training complete.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset, Graph Construction, Evaluation Utilities & Improved Sampler\n\nThis section implements:\n1. `IEEECISDataset` — produces batches of (seq_real, cond_vec, y_real, geo_real) matching the adversarial training loader API.\n2. `build_graph_from_transactions` — constructs PyG `Data` / `Batch` from transaction rows using account/device/merchant nodes.\n3. Evaluation metrics: AUPRC, Precision@K, ECE, Time-to-Detect plus plotting helpers.\n4. Improved sampling: `ddim_sample` and `classifier_guidance` for the DDPM generator.\n\nPlaceholders/TODOs:\n- Update column names and categorical encodings to match your local copy of the dataset.\n- Tune window sizes, embedding dims, and batch sizes for your compute budget.\n","metadata":{}},{"cell_type":"code","source":"# ================================\n# 1) Dataset + DataLoader for IEEE-CIS (Kaggle) - concrete implementation\n# ================================\nimport os\nfrom collections import defaultdict\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nfrom datetime import timedelta\n\n# Assumes transaction CSV has at least:\n# ['TransactionID','TransactionDT','TransactionAmt','ProductCD','card1','card2','addr1','addr2','dist1','device_type','DeviceInfo','isFraud', ...]\n# Adjust mappings if your file differs.\n\nclass IEEECISDataset(Dataset):\n    \"\"\"\n    Produces per-account sequences for transformer input and corresponding graphs for GNN.\n    Expects a transactions dataframe (pandas).\n    Each item: (seq_tensor (L,F), cond_vec (C,), label (0/1), geo_data (torch_geometric Data))\n    \"\"\"\n    def __init__(self, trans_df: pd.DataFrame, seq_len=32, time_col='TransactionDT', label_col='isFraud',\n                 acct_cols=('card1',), device_col='DeviceInfo', merchant_col='ProductCD',\n                 numeric_cols=('TransactionAmt',), cat_cols=('ProductCD', 'card1'), scaler=None):\n        self.df = trans_df.copy()\n        self.seq_len = seq_len\n        self.time_col = time_col\n        self.label_col = label_col\n        self.acct_cols = acct_cols if isinstance(acct_cols, (list,tuple)) else (acct_cols,)\n        self.device_col = device_col\n        self.merchant_col = merchant_col\n        self.numeric_cols = list(numeric_cols)\n        self.cat_cols = list(cat_cols)\n        # Sort transactions by time for each account\n        self.df.sort_values(by=[*self.acct_cols, self.time_col], inplace=True)\n        # Build per-account transaction index mapping\n        self.account_groups = self.df.groupby(list(self.acct_cols))\n        self.accounts = list(self.account_groups.groups.keys())\n        # Pre-fit encoders / scalers\n        self.label_enc = None\n        self.cat_encoders = {c: LabelEncoder() for c in self.cat_cols}\n        for c in self.cat_cols:\n            self.df[c] = self.df[c].fillna('NA')\n            self.cat_encoders[c].fit(self.df[c].astype(str).values)\n        self.scaler = scaler if scaler is not None else StandardScaler()\n        # Fit scaler on numeric cols\n        self.df[self.numeric_cols] = self.df[self.numeric_cols].fillna(0.0)\n        self.scaler.fit(self.df[self.numeric_cols].values)\n        # Build per-account sequence start indices for sampling\n        self.account_indices = []\n        for acct in self.accounts:\n            idxs = self.account_groups.groups[acct].tolist()\n            # we will sample windows of seq_len from these indexes\n            if len(idxs) == 0:\n                continue\n            # record the list of indices for that account\n            self.account_indices.append(idxs)\n        # flatten for len\n        self.flat_account_idx = [i for sub in self.account_indices for i in sub]\n        # handy mapping from TransactionID -> row index\n        self.df.reset_index(drop=True, inplace=True)\n        self.indexed = self.df\n\n    def __len__(self):\n        # number of possible windows approx = number of accounts (we sample per account per epoch)\n        return len(self.account_indices)\n\n    def _build_sequence_for_account(self, acct_idxs):\n        \"\"\"\n        Given a list of row indices for an account (sorted by time), sample the latest seq_len transactions.\n        Returns: seq_array (L,F), cond_vector (C,), label (0/1), graph_data (torch_geometric Data)\n        \"\"\"\n        n = len(acct_idxs)\n        # take last seq_len transactions (pad if needed)\n        sel = acct_idxs[-self.seq_len:] if n >= self.seq_len else ([acct_idxs[0]] * (self.seq_len - n) + acct_idxs)\n        df_seq = self.indexed.loc[sel].copy().reset_index(drop=True)\n        # numeric features\n        num_vals = self.scaler.transform(df_seq[self.numeric_cols].values)  # (L, len(numeric_cols))\n        # categorical features -> one-hot or embedding indices (for prototype we'll use label indices)\n        cat_vals = []\n        for c in self.cat_cols:\n            arr = self.cat_encoders[c].transform(df_seq[c].astype(str).values)\n            cat_vals.append(arr.reshape(-1,1))\n        if len(cat_vals) > 0:\n            cat_stack = np.concatenate(cat_vals, axis=1)\n        else:\n            cat_stack = np.zeros((self.seq_len, 0))\n        # time delta features relative to last tx\n        times = df_seq[self.time_col].astype(float).values\n        time_deltas = (times - times.min()).reshape(-1,1)  # naive; better: differences between txs\n        # combine into feature matrix\n        feat = np.concatenate([num_vals, cat_stack, time_deltas], axis=1).astype(np.float32)\n        # conditional vector (account-level static features): simple choice = last transaction static cols\n        last_row = df_seq.iloc[-1]\n        cond_vec = np.concatenate([\n            np.array([last_row.get(self.device_col, 0)]).astype(object).astype(str) if self.device_col in df_seq.columns else np.array([0]),\n        ])\n        # For prototype, cond_vec as one-hot or embedding indices is not implemented; use placeholder zeros\n        cond_vec = np.zeros(16, dtype=np.float32)\n        # label: if any tx in seq is fraud (you may want last label); we use last tx label\n        label = int(last_row.get(self.label_col, 0))\n        # Build graph_data for the sequence\n        geo_data = build_graph_from_transactions_from_df(df_seq)\n        return torch.tensor(feat, dtype=torch.float32), torch.tensor(cond_vec, dtype=torch.float32), torch.tensor(label, dtype=torch.long), geo_data\n\n    def __getitem__(self, idx):\n        acct_idxs = self.account_indices[idx]\n        return self._build_sequence_for_account(acct_idxs)\n\n\ndef collate_ieee_batch(batch):\n    \"\"\"\n    batch: list of tuples (seq_tensor (L,F), cond_vec (C,), label, geo_data)\n    returns: seq_batch (B, L, F), cond_batch (B, C), y_batch (B,), geo_batch (GeometricBatch)\n    \"\"\"\n    seqs = [x[0] for x in batch]\n    conds = [x[1] for x in batch]\n    labels = [x[2] for x in batch]\n    geos = [x[3] for x in batch]\n    seqs = torch.stack(seqs, dim=0)\n    conds = torch.stack(conds, dim=0)\n    labels = torch.stack(labels, dim=0)\n    geo_batch = GeometricBatch.from_data_list(geos)\n    return seqs, conds, labels, geo_batch\n\n# Usage:\n# trans_df = pd.read_csv(\"transactions.csv\")  # load your file\n# dataset = IEEECISDataset(trans_df, seq_len=32)\n# data_loader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=collate_ieee_batch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# 2) Graph Construction (real pipeline) from IEEE rows\n# ================================\nimport torch_geometric\nfrom torch_geometric.utils import to_undirected\n\ndef build_graph_from_transactions_from_df(df_seq: pd.DataFrame):\n    \"\"\"\n    Converts an account-level sequence dataframe (L rows) into a PyG Data object.\n    Nodes: account node (0), merchant nodes (1..k), device node (k+1)\n    Node features: aggregated features from transactions/merchant/device\n    Edges: account <-> merchant (transaction edges), account <-> device\n    This is a realistic but simple mapping. You can refine it: use merchant IDs, hash devices, cluster merchants, etc.\n    \"\"\"\n    seq_len = len(df_seq)\n    # node features dimension should match what the GNN expects (we can reuse numeric features)\n    # compute account summary feature\n    numeric_cols = ['TransactionAmt']\n    account_feat = df_seq[numeric_cols].mean(axis=0).values.astype(np.float32)  # shape (n_num,)\n    # merchant nodes: each tx gets a merchant node with features (amount, time delta)\n    merchant_feats = df_seq[numeric_cols].fillna(0.0).values.astype(np.float32)  # (L, n_num)\n    # device node: Use last row device info aggregated (placeholder numeric vector)\n    device_feat = np.array([0.0], dtype=np.float32)\n    # concat node features\n    node_feats = np.vstack([account_feat[None, :], merchant_feats, device_feat[None, :]])  # (L+2, n_num)\n    x = torch.tensor(node_feats, dtype=torch.float)  # node features\n\n    # build edges: account idx = 0; merchants idx = 1..L; device idx = L+1\n    src = []\n    dst = []\n    # account <-> merchant edges\n    for m in range(1, 1 + seq_len):\n        src.append(0); dst.append(m)\n        src.append(m); dst.append(0)\n    # account <-> device\n    device_idx = 1 + seq_len\n    src.append(0); dst.append(device_idx)\n    src.append(device_idx); dst.append(0)\n    edge_index = torch.tensor([src, dst], dtype=torch.long)\n    edge_index = to_undirected(edge_index)\n\n    data = GeometricData(x=x, edge_index=edge_index)\n    return data\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# 3) Evaluation metrics & plotting utilities\n# ================================\nfrom sklearn.metrics import average_precision_score, precision_recall_curve\n\ndef auc_pr(y_true, y_score):\n    \"\"\"Average precision (AUPRC).\"\"\"\n    return average_precision_score(y_true, y_score)\n\ndef precision_at_k(y_true, y_score, k):\n    \"\"\"\n    Precision at top k predictions.\n    y_true: array-like of 0/1\n    y_score: predicted score/probability\n    k: integer or fraction (if float between 0 and 1, interpreted as fraction of dataset)\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_score = np.asarray(y_score)\n    n = len(y_true)\n    if 0 < k < 1:\n        k = int(k * n)\n    k = min(max(1, int(k)), n)\n    order = np.argsort(-y_score)\n    topk = order[:k]\n    return y_true[topk].sum() / k\n\ndef expected_calibration_error(y_true, y_prob, n_bins=10):\n    \"\"\"\n    ECE: expected calibration error.\n    \"\"\"\n    y_true = np.asarray(y_true); y_prob = np.asarray(y_prob)\n    bins = np.linspace(0.0,1.0,n_bins+1)\n    bin_ids = np.digitize(y_prob, bins) - 1\n    ece = 0.0\n    for i in range(n_bins):\n        mask = bin_ids == i\n        if mask.sum() == 0:\n            continue\n        acc = y_true[mask].mean()\n        conf = y_prob[mask].mean()\n        ece += (mask.sum() / len(y_prob)) * abs(acc - conf)\n    return ece\n\ndef time_to_detect(y_times, y_true, y_score, threshold):\n    \"\"\"\n    Given arrays of transaction timestamps y_times, labels y_true, and scored probabilities y_score,\n    compute the detection delay for each fraud event: time (or transaction count) from first fraud tx to first detection above threshold.\n    Returns: list of delays (in original time units) for each fraud family occurrence.\n    For simplicity, this implementation expects sorted (by time) arrays and that fraud events are isolated by account.\n    \"\"\"\n    # Group by account or by contiguous fraud events: here we do per-account approach\n    # y_times and y_score are arrays aligned with y_true\n    # For simplicity: find indices where y_true==1 per account; for each account, find time of first fraud and index of first detection\n    # This requires account ids; this function is a template — in practice you will pass grouped arrays.\n    raise NotImplementedError(\"Implement dataset-specific time grouping (per account) for time-to-detect analysis.\")\n\n\n# Plotting helpers\nimport matplotlib.pyplot as plt\ndef plot_pr_curve(y_true, y_score):\n    precision, recall, _ = precision_recall_curve(y_true, y_score)\n    ap = average_precision_score(y_true, y_score)\n    plt.figure(figsize=(6,5))\n    plt.plot(recall, precision, label=f'AP={ap:.3f}')\n    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall Curve'); plt.legend(); plt.grid(True)\n    plt.show()\n\ndef plot_calibration_curve(y_true, y_prob, n_bins=10):\n    bins = np.linspace(0.0,1.0,n_bins+1)\n    binids = np.digitize(y_prob, bins) - 1\n    bin_centers = (bins[:-1] + bins[1:]) / 2\n    accs = []\n    confs = []\n    for i in range(n_bins):\n        mask = binids == i\n        if mask.sum() == 0:\n            accs.append(np.nan)\n            confs.append(np.nan)\n        else:\n            accs.append(y_true[mask].mean())\n            confs.append(y_prob[mask].mean())\n    plt.figure(figsize=(6,6))\n    plt.plot(bin_centers, accs, marker='o', label='Accuracy per bin')\n    plt.plot(bin_centers, confs, marker='x', label='Confidence per bin')\n    plt.plot([0,1],[0,1],'k--', alpha=0.6)\n    plt.xlabel('Confidence'); plt.ylabel('Accuracy'); plt.title('Calibration Curve'); plt.legend(); plt.grid(True)\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}