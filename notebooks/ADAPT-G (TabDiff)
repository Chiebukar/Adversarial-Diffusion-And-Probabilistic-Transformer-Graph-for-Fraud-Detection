{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **ADAPT-G: Adversarial Diffusion And Probabilistic Transformer-Graph for Financial Fraud Detection**\n\n---\n\n## Overview\n\n**ADAPT-G** is a novel hybrid architecture designed for **financial transaction and mobile money fraud detection**.  \nIt combines **adversarial curriculum learning with a diffusion-based generator** to create realistic synthetic fraud scenarios and a **probabilistic Transformer-Graph Neural Network (GNN) detector** to identify both **behavioral** (temporal) and **structural** (relational) anomalies.\n\nOur goal is to **push the boundaries of fraud detection** by addressing the weaknesses of traditional models in catching **stealthy, low-signal fraud patterns** — particularly those that exploit the **network relationships** between entities and **temporal transaction patterns**.\n\n---\n\n## Research Goals\n\n- **Develop** a hybrid adversarial architecture capable of detecting complex fraud signals in transaction networks.\n- **Incorporate** probabilistic reasoning into the detection stage for better uncertainty estimation and high-risk flagging.\n- **Benchmark** against state-of-the-art fraud detection models on real-world financial datasets.\n- **Evaluate** across both temporal and graph-based perspectives to capture full fraud signatures.\n\n---\n\n## Model Architecture\n\nThe **ADAPT-G** framework has two major components:\n\n1. **Diffusion-based Generator**  \n   - Generates high-quality, diverse fraudulent transaction sequences and relational patterns.  \n   - Uses **adversarial curriculum learning** to gradually create harder-to-detect fraudulent scenarios.\n\n2. **Probabilistic Transformer-GNN Detector**  \n   - **Transformer**: Models per-entity temporal transaction behavior.\n   - **Lightweight GNN**: Captures graph-level relational dependencies between entities (accounts, devices, merchants).  \n   - **Probabilistic Output Layer**: Produces calibrated uncertainty scores alongside classification outputs.\n\n---\n\n## Benchmark Models\n\nWe will compare ADAPT-G against:\n\n- **XGBoost** (tabular, feature-engineered baseline)\n- **GCN** (Graph Convolutional Network)\n- **GAT** (Graph Attention Network)\n- **Temporal GNNs** (TGAT, TGN)\n- **LSTM/GRU Autoencoders** (temporal anomaly detection baselines)\n- **TabTransformer** (tabular deep learning baseline)\n\n---\n\n## Datasets\n\nWe will evaluate on **multiple benchmark datasets** for financial/mobile money fraud detection:\n\n- **IEEE-CIS Fraud Detection** (Kaggle)\n- **PaySim** (Mobile money fraud simulation)\n- **Elliptic Dataset** (Bitcoin transaction fraud/illicit activity)\n- **SIMF Dataset** (Mobile money & transaction fraud – simulated and real-world mix)\n\nEach dataset will be preprocessed into both **tabular** and **graph-structured formats** where applicable, ensuring fair comparison across all models.\n","metadata":{}},{"cell_type":"markdown","source":"## **2. Imports & Utilities**\n\n---\n\nThis section loads all **core libraries** required for the ADAPT-G framework and defines key **utility functions** for:\n\n1. **Seeding for reproducibility** — Ensures consistent experimental results.\n2. **Metric calculations** — Precision, Recall, F1-score, AUC-ROC, and more.\n3. **Visualization** — For training/evaluation curves, ROC plots, and confusion matrices.\n","metadata":{}},{"cell_type":"code","source":"# # Install required packages\n# !pip install torch torchvision torch_geometric transformers diffusers scikit-learn pandas matplotlib seaborn tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Imports\n# ================================\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import (\n    precision_score, recall_score, f1_score,\n    roc_auc_score, roc_curve, confusion_matrix,\n    accuracy_score\n)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch_geometric\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv, GATConv, global_mean_pool\nfrom datetime import datetime","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Helper Functions\n# ================================\n\ndef set_seed(seed: int = 42):\n    \"\"\"\n    Sets seed for reproducibility across Python, NumPy, and PyTorch.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    print(f\"[INFO] Seed set to: {seed}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------------------------\n# Metrics\n# -------------------------------------------------\ndef calculate_metrics(y_true, y_pred, y_prob=None):\n    \"\"\"\n    Calculate core classification metrics.\n    y_true: Ground truth labels\n    y_pred: Predicted labels\n    y_prob: Predicted probabilities (for ROC/AUC)\n    \"\"\"\n    metrics_dict = {\n        \"Accuracy\": accuracy_score(y_true, y_pred),\n        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n        \"F1\": f1_score(y_true, y_pred, zero_division=0)\n    }\n    if y_prob is not None:\n        metrics_dict[\"AUC-ROC\"] = roc_auc_score(y_true, y_prob)\n    return metrics_dict\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------------------------\n# Visualization Utilities\n# -------------------------------------------------\ndef plot_loss_curves(train_losses, val_losses):\n    plt.figure(figsize=(8, 5))\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training & Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_roc_curve(y_true, y_prob):\n    fpr, tpr, _ = roc_curve(y_true, y_prob)\n    auc_score = roc_auc_score(y_true, y_prob)\n    plt.figure(figsize=(6, 6))\n    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.3f}')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, labels=None):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(5, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **3. Model Architecture**\n\nThis section defines the two core components of **ADAPT-G**:\n\n---\n\n### **3.1 Generator — TabDiffusion Sample Simulator**  \nWe use **TabDiffusion** to generate **both fraudulent and non-fraudulent transaction samples**.  \n\n- **Conditional Generation:** Generator is conditioned on a label (`fraud = 0` or `1`) along with context features (merchant, device, account profile).  \n- **Dual Simulation:**  \n  - Fraudulent samples: Rare anomalies, generated to mimic realistic fraud signatures.  \n  - Non-fraudulent samples: Plausible “normal” transactions to maintain balance and realism.  \n- **Adversarial Curriculum:** Generator evolves to create increasingly **hard-to-discriminate samples**, forcing the detector to improve.  \n\n> Unlike standard anomaly generation approaches, TabDiffusion provides **balanced synthetic data augmentation** for both classes, addressing fraud rarity while avoiding biased training.  \n\n---\n\n### **3.2 Detector — Probabilistic Transformer-GNN**  \nThe detector integrates **graph structure** and **temporal behavior** to validate whether a given transaction is fraudulent or not:  \n\n- **Graph Encoder (GNN):** Captures structural dependencies across accounts, devices, and merchants.  \n- **Transformer Encoder:** Models sequential patterns in entity transaction histories.  \n- **Fusion Layer:** Combines graph + temporal embeddings.  \n- **Probabilistic Output Layer:**  \n  - Produces fraud classification (fraud vs. non-fraud).  \n  - Estimates prediction uncertainty via **MC Dropout**.  \n\n---\n\n### **3.3 Joint Training Paradigm**  \n- Generator (TabDiffusion) produces both **fraudulent and non-fraudulent samples**.  \n- Detector (Transformer-GNN) learns to confirm whether transactions are truly fraudulent or not.  \n- Adversarial training loop ensures:  \n  - Generator creates challenging, realistic samples.  \n  - Detector improves robustness by distinguishing real vs synthetic and fraud vs non-fraud simultaneously.  ","metadata":{}},{"cell_type":"markdown","source":"### **4.1 Generator: Tabular Diffusion**","metadata":{}},{"cell_type":"code","source":"# ================================================\n# TabDiff-inspired Mixed-Type Conditional Generator\n# ================================================\n# Key features:\n# - Mixed-type: numeric + categorical columns\n# - Continuous-time diffusion with feature-wise learnable schedules\n# - Classifier-free guidance (CFG) for conditional generation (fraud/non-fraud + context)\n# - Categorical decoding via logits + stochastic argmax (approx. to TabDiff's mixed-type sampler)\n# - Detector-guided option (adversarial curriculum) via gradient guidance (optional)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- Utilities ----\n\ndef fourier_t_embed(t, dim=64):\n    \"\"\"Fourier features for continuous time t in [0,1].\"\"\"\n    device = t.device\n    freqs = torch.exp(torch.linspace(math.log(1.0), math.log(1000.0), dim//2, device=device))\n    angles = (t.unsqueeze(-1) * freqs)  # [B, dim/2]\n    return torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1)  # [B, dim]\n\nclass ResidualMLP(nn.Module):\n    \"\"\"Small residual MLP used as score/denoiser backbone (swap with Transformer if desired).\"\"\"\n    def __init__(self, in_dim, hidden=512, layers=3):\n        super().__init__()\n        self.in_dim = in_dim\n        self.net = nn.ModuleList()\n        d = in_dim\n        for _ in range(layers):\n            self.net.append(nn.Sequential(\n                nn.Linear(d, hidden),\n                nn.GELU(),\n                nn.Linear(hidden, d),\n            ))\n        self.norm = nn.LayerNorm(d)\n\n    def forward(self, x):\n        # x: [B, D]\n        for block in self.net:\n            x = self.norm(x + block(x))\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- Generator ----\n\nclass MixedTypeTabDiffusion(nn.Module):\n    \"\"\"\n    TabDiff-inspired generator:\n      - Joint continuous-time diffusion over numeric and categorical embeddings.\n      - Feature-wise learnable log-variance schedules.\n      - Conditional generation (fraud label + context) with classifier-free guidance.\n      - Denoiser predicts noise for numeric dims and categorical embedding dims.\n\n    Numeric features are diffused directly.\n    Categorical features are embedded, diffused in embedding space, and decoded with a classifier head.\n    \"\"\"\n    def __init__(\n        self,\n        num_numeric: int,\n        cat_cardinalities: list,     # e.g., [|DevInfo|, |ProdCD|, ...]\n        cat_embed_dim: int,          # per-categorical embedding size\n        cond_dim: int,               # fraud label + context cond vec\n        hidden=512,\n        denoiser_layers=3,\n        uncond_prob: float = 0.1     # classifier-free guidance dropout prob during training\n    ):\n        super().__init__()\n        self.num_numeric = num_numeric\n        self.cat_cardinalities = cat_cardinalities\n        self.num_cats = len(cat_cardinalities)\n        self.cat_embed_dim = cat_embed_dim\n        self.uncond_prob = uncond_prob\n\n        # Categorical embeddings & decoders\n        self.cat_embeds = nn.ModuleList([\n            nn.Embedding(card, cat_embed_dim) for card in cat_cardinalities\n        ])\n        self.cat_decoders = nn.ModuleList([\n            nn.Linear(cat_embed_dim, card) for card in cat_cardinalities\n        ])\n\n        # Feature-wise learnable schedules (log-variance at t=1; interpolated over t via simple param)\n        # Separate for numeric and for each categorical embedding dimension\n        self.log_var_num = nn.Parameter(torch.zeros(num_numeric))                # [F_num]\n        self.log_var_cat = nn.Parameter(torch.zeros(self.num_cats, cat_embed_dim))  # [C, E]\n\n        # Conditioner to fuse (x_t, t_embed, cond) -> latent\n        # We flatten numeric + cat-embeddings to a single vector\n        input_dim = num_numeric + self.num_cats * cat_embed_dim\n        self.time_mlp = nn.Sequential(nn.Linear(64, 128), nn.GELU(), nn.Linear(128, 128))\n        self.cond_proj = nn.Sequential(nn.Linear(cond_dim, 128), nn.GELU())\n\n        # Denoiser (score network)\n        self.denoiser = ResidualMLP(in_dim=input_dim + 128 + 128, hidden=hidden, layers=denoiser_layers)\n\n        # Output heads predict noise in numeric dims + cat-embed dims\n        self.head_num = nn.Linear(input_dim + 128 + 128, num_numeric)              # noise for numeric\n        self.head_cat = nn.Linear(input_dim + 128 + 128, self.num_cats * cat_embed_dim)  # noise for all cat embeds\n\n    # ----- diffusion schedule (continuous-time) -----\n\n    def _alpha_sigma(self, t, kind='num'):\n        \"\"\"\n        Compute per-feature alpha(t) and sigma(t) for continuous-time VP-like diffusion.\n        We use a simple schedule with learnable log-variance endpoints (feature-wise).\n        \"\"\"\n        # t: [B]\n        B = t.shape[0]\n        if kind == 'num':\n            log_var = self.log_var_num  # [F_num]\n            Fnum = log_var.shape[0]\n            # simple linear schedule over t in [0,1]: sigma(t) = exp( t * log_var/2 )\n            sigma_t = torch.exp(0.5 * (t.unsqueeze(1) * log_var.unsqueeze(0)))          # [B, Fnum]\n            alpha_t = torch.sqrt(torch.clamp(1.0 - sigma_t**2, min=1e-5))               # [B, Fnum]\n            return alpha_t, sigma_t\n        else:\n            # categorical embedding dims\n            log_var = self.log_var_cat.view(1, self.num_cats, self.cat_embed_dim)      # [1,C,E]\n            sigma_t = torch.exp(0.5 * (t.view(B,1,1) * log_var))                       # [B,C,E]\n            alpha_t = torch.sqrt(torch.clamp(1.0 - sigma_t**2, min=1e-5))              # [B,C,E]\n            return alpha_t, sigma_t\n\n    # ----- forward (training noise) -----\n\n    def _forward_diffuse(self, x_num0, x_cat_emb0, t):\n        \"\"\"\n        Add noise at time t.\n        x_num0: [B, Fnum]\n        x_cat_emb0: [B, C, E]\n        \"\"\"\n        B = x_num0.size(0)\n        # numeric\n        alpha_n, sigma_n = self._alpha_sigma(t, kind='num')           # [B, Fnum]\n        eps_n = torch.randn_like(x_num0)\n        x_n_t = alpha_n * x_num0 + sigma_n * eps_n\n\n        # categorical embeddings\n        alpha_c, sigma_c = self._alpha_sigma(t, kind='cat')           # [B, C, E]\n        eps_c = torch.randn_like(x_cat_emb0)\n        x_c_t = alpha_c * x_cat_emb0 + sigma_c * eps_c\n\n        return (x_n_t, eps_n), (x_c_t, eps_c)\n\n    # ----- denoiser -----\n\n    def _predict_noise(self, x_n_t, x_c_t, t, cond_vec):\n        \"\"\"\n        Predict noise components for numeric and categorical embeddings.\n        x_n_t: [B, Fnum]\n        x_c_t: [B, C, E]\n        t: [B]\n        cond_vec: [B, Dcond]\n        \"\"\"\n        B = x_n_t.size(0)\n        # Flatten cat embeddings\n        x_cat_flat = x_c_t.reshape(B, self.num_cats * self.cat_embed_dim)  # [B, C*E]\n        time_feat = self.time_mlp(fourier_t_embed(t, 64))                  # [B, 128]\n\n        # classifier-free guidance dropout during training\n        if self.training and self.uncond_prob > 0.0:\n            mask = (torch.rand(B, device=cond_vec.device) < self.uncond_prob).float().unsqueeze(1)\n            cond_in = (1.0 - mask) * cond_vec  # drop cond to zero for some samples\n        else:\n            cond_in = cond_vec\n        cond_feat = self.cond_proj(cond_in)                                 # [B, 128]\n\n        h_in = torch.cat([x_n_t, x_cat_flat, time_feat, cond_feat], dim=1)  # [B, D_in]\n        h = self.denoiser(h_in)                                             # [B, D_in]\n        noise_num = self.head_num(h)                                        # [B, Fnum]\n        noise_cat = self.head_cat(h).view(B, self.num_cats, self.cat_embed_dim)  # [B, C, E]\n        return noise_num, noise_cat\n\n    # ----- loss -----\n\n    def training_loss(self, x_num0, x_cat_ids, cond_vec):\n        \"\"\"\n        x_num0:   [B, Fnum]            (normalized numeric features)\n        x_cat_ids:[B, C]               (categorical indices per column)\n        cond_vec: [B, Dcond]           (context + fraud label)\n        \"\"\"\n        device = x_num0.device\n        B = x_num0.size(0)\n\n        # embed categories\n        x_cat_emb0 = []\n        for i, emb in enumerate(self.cat_embeds):\n            x_cat_emb0.append(emb(x_cat_ids[:, i]))\n        x_cat_emb0 = torch.stack(x_cat_emb0, dim=1)  # [B, C, E]\n\n        # sample continuous time t ~ U(0,1)\n        t = torch.rand(B, device=device)\n\n        # diffuse\n        (x_n_t, eps_n), (x_c_t, eps_c) = self._forward_diffuse(x_num0, x_cat_emb0, t)\n\n        # predict noise\n        eps_n_hat, eps_c_hat = self._predict_noise(x_n_t, x_c_t, t, cond_vec)\n\n        # MSE losses\n        loss_num = F.mse_loss(eps_n_hat, eps_n)\n        loss_cat = F.mse_loss(eps_c_hat, eps_c)\n\n        return loss_num + loss_cat, {'loss_num': loss_num.detach(), 'loss_cat': loss_cat.detach()}\n\n    # ----- sampling with classifier-free guidance -----\n\n    @torch.no_grad()\n    def sample(self, batch_size, cond_vec, steps=50, guidance_w=2.0, stochastic_round=True, device=None):\n        \"\"\"\n        Generate samples with discretized continuous-time steps (DDIM-like).\n        - guidance_w: CFG weight. We compute eps = (1+w)*eps_cond - w*eps_uncond.\n        - stochastic_round: stochastic categorical decode to reduce bias.\n        Returns numeric features and categorical ids.\n        \"\"\"\n        device = device or cond_vec.device\n        B = batch_size\n        # init with pure noise at t=1\n        x_n = torch.randn(B, self.num_numeric, device=device)\n        x_c = torch.randn(B, self.num_cats, self.cat_embed_dim, device=device)\n\n        ts = torch.linspace(1.0, 0.0, steps+1, device=device)  # t_0=1 -> t_S=0\n        for s in range(steps):\n            t_cur = ts[s].repeat(B)\n            t_next = ts[s+1].repeat(B)\n\n            # predict noise with CFG: need cond and uncond predictions\n            # prepare uncond cond-vec (zeros)\n            cond_uncond = torch.zeros_like(cond_vec)\n\n            eps_n_c, eps_c_c = self._predict_noise(x_n, x_c, t_cur, cond_vec)\n            eps_n_u, eps_c_u = self._predict_noise(x_n, x_c, t_cur, cond_uncond)\n\n            eps_n = (1+guidance_w)*eps_n_c - guidance_w*eps_n_u\n            eps_c = (1+guidance_w)*eps_c_c - guidance_w*eps_c_u\n\n            # compute alphas/sigmas at t_cur and t_next\n            a_n_cur, s_n_cur = self._alpha_sigma(t_cur, 'num')\n            a_c_cur, s_c_cur = self._alpha_sigma(t_cur, 'cat')\n            a_n_next, s_n_next = self._alpha_sigma(t_next, 'num')\n            a_c_next, s_c_next = self._alpha_sigma(t_next, 'cat')\n\n            # predict x0 (per feature)\n            x0_n = (x_n - s_n_cur * eps_n) / (a_n_cur + 1e-6)\n            x0_c = (x_c - s_c_cur * eps_c) / (a_c_cur + 1e-6)\n\n            # deterministic update (DDIM-like interpolation)\n            x_n = a_n_next * x0_n + s_n_next * eps_n\n            x_c = a_c_next * x0_c + s_c_next * eps_c\n\n        # decode categories from embeddings\n        cat_ids = []\n        for j, dec in enumerate(self.cat_decoders):\n            # project the j-th embedding to logits\n            logits = dec(x_c[:, j, :])  # [B, |cat_j|]\n            if stochastic_round:\n                # gumbel sampling\n                g = -torch.log(-torch.log(torch.rand_like(logits)))\n                cat_ids.append(torch.argmax(logits + g, dim=-1))\n            else:\n                cat_ids.append(torch.argmax(logits, dim=-1))\n        cat_ids = torch.stack(cat_ids, dim=1)  # [B, C]\n\n        return x_n, cat_ids\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# x_num0: [B, Fnum] normalized numeric; x_cat_ids: [B, C] categorical indices\n# cond_vec: [B, Dcond] built from device/account/merchant + fraud_label (0/1)\ngen = MixedTypeTabDiffusion(num_numeric=Fnum, cat_cardinalities=cat_cards, cat_embed_dim=32, cond_dim=Dcond).to(device)\nopt_g = torch.optim.AdamW(gen.parameters(), lr=2e-4, weight_decay=1e-4)\n\ngen.train()\nfor step, (x_num0, x_cat_ids, cond_vec) in enumerate(train_loader):\n    x_num0, x_cat_ids, cond_vec = x_num0.to(device), x_cat_ids.to(device), cond_vec.to(device)\n    loss, parts = gen.training_loss(x_num0, x_cat_ids, cond_vec)\n    opt_g.zero_grad(set_to_none=True)\n    loss.backward()\n    opt_g.step()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gen.eval()\n# Build cond vectors for fraud=0 and fraud=1 (plus context)\nx_num_fake_0, x_cat_fake_0 = gen.sample(batch_size=512, cond_vec=cond_vec_nonfraud, steps=80, guidance_w=2.0, device=device)\nx_num_fake_1, x_cat_fake_1 = gen.sample(batch_size=512, cond_vec=cond_vec_fraud,    steps=80, guidance_w=2.0, device=device)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}